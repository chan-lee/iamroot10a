[2014.01.25] review
arch/arm/kernel/setup.c - setup_arch()

1. 저번 시간의 setup_machine_fdt()에 이어 setup_machine_tags() 함수를 봄
    atags_pointer 정보가 담겨있는 address를 기반으로 fdt인가를 확인한후
    fdt가 아닐 경우 setup_machine_tags를 호출한다.
    우리는 atags를 사용하지 않지만 살펴보면 setup_machine_fdt()와 비슷한 구조를
    가지고 있다. machine_desc들로부터 적당한 machine_desc를 찾아내고, atags 정보를
    저장, parse한다.

2. 그 후 setup_machine_fdt() 혹은 tags()로 부터 boot_coomand_line을 cmd_line에 저장한 후,
3. early_param을 파싱하여 earlycon=, console= 옵션을 얻어낸다.
4. 그리고 memory bank를 address순으로 정렬한다. (atags사용시 의미가 있는지는 잘 모르겠다.)

------------------------------------------------------------
[2014.01.25] normal
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
        arch/arm/mm/init.c - bootmem_init()
            arch/arm/mm/init.c - arm_bootmem_free()
                arch/mm/page_alloc.c - free_area_init_node()
                    arch/mm/page_alloc.c - free_area_init_core()

1.                    arch/mm/page_alloc.c - init_currently_empty_zone()
    해당 함수는 zone의 wait_table과 free_list를 할당하고 초기화하는 함수이다.

2.                    arch/mm/page_alloc.c - memmap_init() = memmap_init_zone()
    해당 함수는 page에 zone, nid, page_count, mapcount 등을 설정.
    중간에 set_pageblock_migratetype이란 함수가 나오는데, pageblock의 개념을 잘 모르겠다.
    sparse에서 use_map(section의 시작 포인터)이 pageblock_flag에 저장되었는데, 이것이 왜
    pageblock인지 이유를 알수 없음. use_map이 pageblock인지 조차 잘 모르겠다. TODO


------------------------------------------------------------
[2014.02.15] review
arch/arm/kernel/setup.c - setup_arch()
1.    arch/arm/mm/mmu.c - sanity_check_meminfo()
    sanity_check_meminfo()함수는 membank를 순환하면서 highmem인지 검출하고,
    겹쳐 있는 부분을 나누며, high_memory, memblock_limit등을 설정한다.
    __pa(vmalloc_min - 1) + 1의 경우 vmalloc_min은 high memory의 시작 위치를
    나타내고(760M = 0xEF800000), __pa 함수는 물리 주소로 변환, -1/+1은 잘못된
    변환을 막기 위해서 사용한다. 자세한 내용은 C팀의 후기를 참조하도록 한다.

    - vmalloc_min과 -1/+1에 대한 설명 
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&page=3&document_srl=185255
    - __pa, __virt_to_phys() 함수에 대한 설명
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905

------------------------------------------------------------
[2014.02.15] 후반
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
1.  paging_init()함수 내부 아랫쪽의 zero_page를 flush시키는 곳부터 시작.
    zero_page는 읽기를 위한 page로서 효율을 위해 만들어진 페이지이며,
    쓰기요청이 들어올경우 COW로 작동한다.
    아랫부분에 __flush_dache_page 함수가 있는데, 왜 flush를 하는지와
    내부 구현은 cache에 대한 이해가 부족에 미루기로 한다.

arch/arm/kernel/setup.c - setup_arch()
2.  request_standard_resources에서 iomem_resource와 iomem_resource tree에
    system ram, kernel code, video ram, lp port등을 할당한다.
3.  unflatten_device_tree로 나머지 device  tree를 완성하고, cpu, psci, smp설정을 한다.
    그중 smp_build_mpidr_hash함수는 pass. reverse_crashkernel을 위한 공간도 만들어서
    iomem_resource에 추가한다.
5.  mdesc->init_early() 는 있을듯한데 없다.

------------------------------------------------------------
[2014.02.22] review
setup_arch() - arch/arm/kernel/setup.c 
1.  arm_memblock_init() - arch/arm/mm/init.c
    meminfo로부터 memblock.memory->region을 만들고,
    kernel text/bss, initrd, swapper_pg_dir, dt내의 reverve영역,
    mdesc->reserve영역, DMB contiguos 부분을 memblock.reserve에 추가한다.
    memblock_add -> memblock_add_region -> memblock_double_array() 부분은 
    어느 부분까지 동작하는지 잘 모르겠으므로 패스한다.
    DT level : bank 정보로 부터 meminfo를 만듬
    memblock level : meminfo로 부터 memblock정보를 region으로 채움

    paging_init() - arch/arm/mm/mmu.c
2.      build_mem_type_table() - arch/arm/mm/mmu.c
    cachepolicy와 memtype을 설정한다. 자세한 사항은 다음을 참조하자.
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905
 
3. prepare_page_table -preview
    32 bits를 1,2차 table과 page로 나누면, 31~20(1차)/19~12(2차)/11~0(page size)로 나눠지게 된다.
    그러므로 1차table (PGD)의 entries는 4096개가 되고, 2차 table(PTE)의 entries는 256개가 되며,
    page size는 4K가 된다.
    PTE : 256개의 enties는 1K(256 * 4bytes)의 공간을 차지하게 되는데(이때 커버하는 page크기는 1M)
          ARM의 경우 HW의 entry에 dirty bit같은 부가 정보가
          없으므로 linux용 entry가 따로 필요하게 된다. 그러다 보니 pte가 차지하는 공간은
          2K로 늘어나게 된다.
          거기에 pte의 크기가 page의 크기가 되어야 하기 때문에 2쌍이이 들어갈수 있게되고
          linux kernel 입장에서는 총 entries는 512개가 되고 커버하는 page크기는 2M가 된다.
          mmu 입장: 1K, 256 entries, 1M memory cover
          kernel 입장: 4K, 512 enties, 2M memory cover
    PGD : 4096개의 entries가 필요하고 이에 대한 크기는 4096 * 4bytes = 16K가 된다.
          하지만 linux kernel 입장에서는 하나의 PTE는 512개의 entries를 가지게 되고, 결국
          2048개만 필요하게 된다.
          mmu 입장: 16K, 4096 enties, 4G memory cover
          kernel 입장: 16K, 2048 enties, 4G memory cover

------------------------------------------------------------
[2014.02.22] 후반
start_kernel() - init/main.c 
1. 아래와 같은 함수들을 살펴 봄
	mm_init_owner() - kernel/fork.c // init_mm의 owner를 init_task로 함
	mm_init_cpumask() - include/linux/mm_types.h
	setup_command_line() - init/main.c // p.265 참조
	setup_nr_cpu_ids()
2. per_cpu에 대하여 공부함.
    - per_cpu는 언제 사용하는가?
        percpu 의 개념 http://studyfoss.egloos.com/5375570
        percpu 의 사용 http://blog.naver.com/PostView.nhn?blogId=nix102guri&logNo=90098904482
    - thread_safe/ re-entrant 가능한가?
    - thread는 cpu를 옮겨 다니는가?
        work-queue http://studyfoss.egloos.com/5626173

--------------------------------------------------------------------------------
[2014.03.01] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
1.      prepare_page_table() - arch/arm/mm/mmu.c
    - PAGE_OFFSET (가상주소0~3G) 까지 pmd를 clear한다.
    - high memory (가상주소3G + 780M)부터 VMALLOC_START까지 pmd를 clear한다.
        왜 VMALLOC_END가 아닌 VMALLOC_START인지는 잘 모르겠다.
2. 의문 : pmd 및 pte는 가상 주소인가? 물리 주소인가?
        
--------------------------------------------------------------------------------
[2014.03.01] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
	    pcpu_embed_first_chunk() - mm/percpu.c
	        pcpu_build_alloc_info() - mm/percpu.c
1. cpu를 group으로 나눈후 각 그룹에 적용했을 때 낭비가 적은 unit per allocs를
    찾는다. alloc과 unit의 상관관계를 알기가 어려워 헤매었다. 다음시간에 마저하도록한다.
    참조 : http://studyfoss.egloos.com/5377666

--------------------------------------------------------------------------------
[2014.03.08] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
        low-mem, dma, device, highmem 영역에 대해 mapping을한다.
        create_mapping() 구현 부분은 너무 복잡해서 책을 참조(p.211)하기로 하고
        넘어간다.

1.      map_lowmem() - arch/arm/mm/mmu.c
	    lowmem 영역에 대해 pgd, pud, pmd, pte를 설정한다.
2.      dma_contiguous_remap() - arch/arm/mm/mda-mapping.c
        dma 영역에 대해 다시 mapping
3.      devicemaps_init(mdesc) - arch/arm/mm/mmu.c
        각 장치에 대해 mapping, gap을 메꾸고, pci를 static_vmlist에 등록한다.
	    mapping 끝부분에 있는 pci_reserve_io()는
        PCI 영역을 static_vmlist에 추가하는 함수이다.
	    vmalloc에서 중요한 구조체는 struct vm_struct 와 struct static_vm가
        있는데, staic_vm은 staic_vmlist의 node고 그것들이 각 vm_struct를
        list로 들고 있다.
        io에 의한 pmd_gap을 메꿔주는 자료는 iamroot에 있다. 링크 필요.
4.      kmap_init() - arch/arm/mm/mmu.c
        p.215 TODO  왜 하나의 PMD가 필요한지 잘 모르겠다.
5.      kmemleak.c에는 kernel에서 메모리 누수 및 디버깅 검출을 위한 함수들이 있다.
        kmemleack 호출 위치 수정요망
--------------------------------------------------------------------------------
[2014.03.08] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
1.      pcpu_embed_first_chunk() - mm/percpu.c
        percpu를 위한 first chuck를 만든후 각 percpu offset을 기록한다.
        자세한 내부 루틴은 다음을 참조한다.
        http://studyfoss.egloos.com/viewer/5377666
2.      smp_prepare_boot_cpu() - arch/arm/kernel/smp.c
        booting cpu의 per_cpu offet을 기록한다.
3.      build_all_zonelists() - mm/page_alloc.c
	    set_zonelist_order()를 호출하여 zonelist의 order를 결정한다.
        zone별로 혹은 node별로...

--------------------------------------------------------------------------------
[2014.03.22] 
start_kernel() - init/main.c
	build_all_zonelists() end 
1. mminit_verify_zonelist() //zonelist 검증.
2. cpuset_init_current_mems_allowed() //mems_allowd 비트맵에 시스템의 모든 노드를 set함.
3. nr_free_pagecache_pages(); //@@ highmem에서 이동 가능한 프리페이지수를 구함.
4. @@ mobility를 할만큼 충분한 가용 페이지가 없으면 mirgration을 하지 않겠다.
 

--------------------------------------------------------------------------------
[2014.03.28]
start_kenrel() - page_alloc_init()

1. hotcpu_notifier()
	- notifier_block 구조체 타입의 page_alloc_cpu_notify_nb를 만들고 우선순위를 0으로 page_alloc_cpu_notify_nb에 등록

	.page_alloc_cpu_notify()
		.lru_add_drain_cpu(cpu)
			TODO: LRU에 대해서

		.drain_page(cpu) - 2014.4.5 시작..


--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
[2014.04.05]
start_kenrel() - page_alloc_init()

[앞시간]
1. lwn: control groups 관련 article reading
        (cgroup의 과거와 현재 그리고 미래)

[뒷시간]
1. understanding linux virtual memory management Chapter.10 Reading: LRU
page replacement policy and Pagecache
2. lru_add_drain_cpu 복습: lru_add_pvec, lru_rotate_pvecs,
lru_deactivate_pvecs 등의 의미와 Pagecache와의 관계
1. drain_page() 하던 중 종료 (2014.04.12 부터 다시)

--------------------------------------------------------------------------------
[2014.04.12]
understanding the linux virtual memory manager
Chapter 2 - Describing Physical Memory
책에서는 각 bank는 node라 불리고 노드를 나타내는 자료 구조는
struct pglist_data {} pg_data_t 이다.
NUMA의 경우 pg_data_t의 list인 pgdat_list로 나타내며, 
UMA의 경우 contig_page_data로 되어있다.
ZONE에 대한 설명은 생략하고, 34Page를 보면 각 구조체의 관계가 나와있다.
pg_data_t -> node_zones -> ZONE_XXX -> node_mem_map(책에는 zone_mem_map으로 나와있음) -> page

Chapter 2.1 Nodes
pg_data_t에 대하여 설명하고 있는데, 책을 참조하고
node_start_paddr은 node_start_pfn으로 변경된듯하고,
node start mapnr은 사라진듯하고, 다음 node를 가리키는
중요한 데이터인 node_next가 사라졌다. 이 부분에 대한 변경이 
현재 코드에 사라진 pgdat_list와 관련이 있는것 같다. (pgdat_list와 pg_list_data랑 혼동하지 말것)

--------------------------------------------------------------------------------
[2014.04.19]
Chapter 2.2 Zones
zone_struct가 zone으로 바뀐듯하다.

2.2.1 Zone Watermarks
zone watermarks는 메모리가 모자를 때 pageout damenon인 kswapd을 언제 깨우느냐에 대한
수위이다.
enum zone_watermarks {
	WMARK_MIN, // free_area_init_core()에서 초기화 되며, direct_recalim path로 극심하게 메모리가 모자른 수위
	WMARK_LOW, // kswapd 이 깨어나서 freeing을 하기 시작하는 수위. 보통 min의 두배
	WMARK_HIGH, // kswapd 이 잠드는 수위. 보통 min의 3배
	NR_WMARK
};

2.2.2 Calculating the Size of Zones
책에서는 setup_memory()에서 각종 min_low_pfn, max_low_pfn, max_pfn을 계산한다고
나왔는데, setup_memory 함수는 없어진듯하다. 대신에 arch/arm/mm/init.c에 bootmem_init을
보면 find_limits로 찾는다.
min_low_pfn은 kernel image 다음의 첫 페이지
max_low_pfn은 ZONE_NORMAL의 끝부분 (kernel/userspace를 나누는 PAGE_OFFSET과도 관련이 있다.)
max_pfn은 적은memory machine에서는 max_low_pfn과 같다. 그럼 큰 메모리에서는?
그리고 위의 세 값은 high memory 위치를 계산하기 위해 바로 넘겨진다.

2.2.3 Zone Wait Queue Table
page를 이용하려는 process들은 wait queue에 들어가게 되는데, page마다
운영하는 것은 공간을 너무 많이 차지한다. 그래서 zone에 wait_table을 만들고
한꺼번에 관리하는데 하나의 큐를 사용하면 unlock시 모든 process가 깨어나는
(thundering heard) 문제가 발생한다.
그래서 hash table을 만들고 page들을 몇개씩(아마도 256개=PAGE_PER_WAITQUEUE?) 모아서
wait queue를 관리한다. hash collision이 발생하면 같은 hash index에 있는 process들이 모두
깨어 나긴 하지만 그래도 공간을 절약하는것이 더 낫다.
자세한 설명은 책과 include/linux/mmzone.h의 zone struct의 wait_table 멤버 설명에 나와있다.
그리고 책에서는 free_area_init_core() 에서 한다고 했는데
mm/page_alloc.c 를 보면 zone_wait_table_init() 함수에서 zone->wait_table을 계산한다.
책에 보면 wait_queue_siz를 계산하는 부분이 나오는데 log2를 하고 있어서 좀 이상하다.

2.3 Zone Initialization
paging_init()
UMA: free_area_init() -> free_area_init_node(0) -> free_area_init_core()
NUMA: free_area_init_node(0) -> free_area_init_core()

2.4 Initializing mem_map
UMA: global mem_map은 pglist_data(0)의(실제로는 contig_pgdat) 의 node_mem_map과 동일하며
alloc_node_mem_map() 함수에서 할당 받는다.
NUMA: global mem_map은 PAGE_OFFSET을 가리키고 그 virtual array 안에
pg_dat의 node_mem_map가 가리키는 page들의 주소가 저장되어 있다.
현재는 없어진 zone 안의 zone_mem_map이 가리키는 주소 또한 virtual array 안에 저장되어 있다.

ex)
UMA: 실제 map 주소 (0x12345678), global mem_map(0x12345678), node_mem_map(0x12345678)
NUMA: 0번 노드의 map 주소 (0x12345678), global mem_map(PAGE_OFFSET), PAGE_OFFSET[XX](0x12345678)
=> 확실치가 않다.

--------------------------------------------------------------------------------
[2014.04.26]
Chapter 2.5. Pages
struct page 에 대한 설명
모든 물리적 페이지 프레임은 struct page 로 관리됨
페이지의 status 를 추적하기 위해서

[list]
list_head 가 page 를 list로 관리함.
2.xv설명) clean_pages list, dirt_pages list, locked_pages 리스트가
존재함.
3.xv) 지금은 확실하지 않다.

[address_space* mapping]
memory mapped -> address space 가리킴.
1. 파일인경우: 파일 조작 address_space
2. anonymous & mapping is setted: swap address space

[unsigned long index]
1. 파일인 경우: 파일의 offset
2. swap_space: space address space offset
3. being freed: order of the block being freed -> stored in index -> 3.x
v에서는 이것이 void* freelist로 관리됨(3.x에서는 union을 이용한다.)

[next_hash]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[count]

[flags]

[lru]

[pprev_has]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[buffers]
-> 3.x에서 buffer_head 사용에 관한 논의(bio를 씀?) (3.x v에서 확인 못함)
ref) http://blog.naver.com/kkn2988?Redirect=Log&logNo=141569528

[virtual]
void* virtual: 커널 메모리 영역(3~4GB)에서 ZONE_NORMAL까지는 direct mapping
되지만, kernel space에서 할당하는 ZONE_HIGHMEM영역은 kmap()으로 매핑된다.
이 kmap()으로 관리되는 영역을 virtual이 가리킴.

Pageflag
-- include/linux/page-flags.h 에서 확인 가능

Chapter 2.6. Mapping Pages to Zones
1. 2.4에서는 struct page마다 zone을 가리키는 포인터가 있었지만 2.6
이후로 삭제되고, 대신 SHIFT를 이용해서 접근함. zone을 위해서 pageflag의
일부 공간을 이용한다.
2. zone_table 의 자료 구조가 있는가? 3.x에서 아직 못찾았음.

Chapter 2.7. High Memory
32bit machine에서 4GB이상의 물리 메모리를 사용하기 위한 PAE등에 대한 설명

Chapter 2.8. What's New in 2.6
1. Zones 자료구조에 업데이트 된 부분들
: zone->lock, zone->lru_lock, zone->pageset과 같이 spinlock contention이 높은
자료구조들을 서로 다른 cacheline에 배치시키기 위해 zone 내부에 padding을 두는
trick을 사용함.

2. per_cpu_page 자료구조에 대한 의문점들을 아직 가지고 있다.

3. page_state 자료구조는 3.x에서는 사라진 것으로 보인다.

Chapter 3. Page Table Management

pgd_t datatype:
./arch/arm/include/asm/page.h 의 149부터 153번째 줄 참고(3단계인지
2단계인지 아직 명확하지 않음)

unsigned integer 를 structure로 define한 이유? :잘못된 사용을 막기 위해 +
PAE의 4bit를 위해: page granularity때문에 32bit모두 다 필요하지는
않다.((다시 확인해야함)

page granularity 만큼의 remaining bits는 다양한 용도로 사용(PAE 확장,
protection 등등)

--------------------------------------------------------------------------------
[2014.05.10]

git push test
