[2014.01.25] review
arch/arm/kernel/setup.c - setup_arch()

1. 저번 시간의 setup_machine_fdt()에 이어 setup_machine_tags() 함수를 봄
    atags_pointer 정보가 담겨있는 address를 기반으로 fdt인가를 확인한후
    fdt가 아닐 경우 setup_machine_tags를 호출한다.
    우리는 atags를 사용하지 않지만 살펴보면 setup_machine_fdt()와 비슷한 구조를
    가지고 있다. machine_desc들로부터 적당한 machine_desc를 찾아내고, atags 정보를
    저장, parse한다.

2. 그 후 setup_machine_fdt() 혹은 tags()로 부터 boot_coomand_line을 cmd_line에 저장한 후,
3. early_param을 파싱하여 earlycon=, console= 옵션을 얻어낸다.
4. 그리고 memory bank를 address순으로 정렬한다. (atags사용시 의미가 있는지는 잘 모르겠다.)

------------------------------------------------------------
[2014.01.25] normal
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
        arch/arm/mm/init.c - bootmem_init()
            arch/arm/mm/init.c - arm_bootmem_free()
                arch/mm/page_alloc.c - free_area_init_node()
                    arch/mm/page_alloc.c - free_area_init_core()

1.                    arch/mm/page_alloc.c - init_currently_empty_zone()
    해당 함수는 zone의 wait_table과 free_list를 할당하고 초기화하는 함수이다.

2.                    arch/mm/page_alloc.c - memmap_init() = memmap_init_zone()
    해당 함수는 page에 zone, nid, page_count, mapcount 등을 설정.
    중간에 set_pageblock_migratetype이란 함수가 나오는데, pageblock의 개념을 잘 모르겠다.
    sparse에서 use_map(section의 시작 포인터)이 pageblock_flag에 저장되었는데, 이것이 왜
    pageblock인지 이유를 알수 없음. use_map이 pageblock인지 조차 잘 모르겠다. TODO


------------------------------------------------------------
[2014.02.15] review
arch/arm/kernel/setup.c - setup_arch()
1.    arch/arm/mm/mmu.c - sanity_check_meminfo()
    sanity_check_meminfo()함수는 membank를 순환하면서 highmem인지 검출하고,
    겹쳐 있는 부분을 나누며, high_memory, memblock_limit등을 설정한다.
    __pa(vmalloc_min - 1) + 1의 경우 vmalloc_min은 high memory의 시작 위치를
    나타내고(760M = 0xEF800000), __pa 함수는 물리 주소로 변환, -1/+1은 잘못된
    변환을 막기 위해서 사용한다. 자세한 내용은 C팀의 후기를 참조하도록 한다.

    - vmalloc_min과 -1/+1에 대한 설명 
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&page=3&document_srl=185255
    - __pa, __virt_to_phys() 함수에 대한 설명
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905

------------------------------------------------------------
[2014.02.15] 후반
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
1.  paging_init()함수 내부 아랫쪽의 zero_page를 flush시키는 곳부터 시작.
    zero_page는 읽기를 위한 page로서 효율을 위해 만들어진 페이지이며,
    쓰기요청이 들어올경우 COW로 작동한다.
    아랫부분에 __flush_dache_page 함수가 있는데, 왜 flush를 하는지와
    내부 구현은 cache에 대한 이해가 부족에 미루기로 한다.

arch/arm/kernel/setup.c - setup_arch()
2.  request_standard_resources에서 iomem_resource와 iomem_resource tree에
    system ram, kernel code, video ram, lp port등을 할당한다.
3.  unflatten_device_tree로 나머지 device  tree를 완성하고, cpu, psci, smp설정을 한다.
    그중 smp_build_mpidr_hash함수는 pass. reverse_crashkernel을 위한 공간도 만들어서
    iomem_resource에 추가한다.
5.  mdesc->init_early() 는 있을듯한데 없다.

------------------------------------------------------------
[2014.02.22] review
setup_arch() - arch/arm/kernel/setup.c 
1.  arm_memblock_init() - arch/arm/mm/init.c
    meminfo로부터 memblock.memory->region을 만들고,
    kernel text/bss, initrd, swapper_pg_dir, dt내의 reverve영역,
    mdesc->reserve영역, DMB contiguos 부분을 memblock.reserve에 추가한다.
    memblock_add -> memblock_add_region -> memblock_double_array() 부분은 
    어느 부분까지 동작하는지 잘 모르겠으므로 패스한다.
    DT level : bank 정보로 부터 meminfo를 만듬
    memblock level : meminfo로 부터 memblock정보를 region으로 채움

    paging_init() - arch/arm/mm/mmu.c
2.      build_mem_type_table() - arch/arm/mm/mmu.c
    cachepolicy와 memtype을 설정한다. 자세한 사항은 다음을 참조하자.
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905
 
3. prepare_page_table -preview
    32 bits를 1,2차 table과 page로 나누면, 31~20(1차)/19~12(2차)/11~0(page size)로 나눠지게 된다.
    그러므로 1차table (PGD)의 entries는 4096개가 되고, 2차 table(PTE)의 entries는 256개가 되며,
    page size는 4K가 된다.
    PTE : 256개의 enties는 1K(256 * 4bytes)의 공간을 차지하게 되는데(이때 커버하는 page크기는 1M)
          ARM의 경우 HW의 entry에 dirty bit같은 부가 정보가
          없으므로 linux용 entry가 따로 필요하게 된다. 그러다 보니 pte가 차지하는 공간은
          2K로 늘어나게 된다.
          거기에 pte의 크기가 page의 크기가 되어야 하기 때문에 2쌍이이 들어갈수 있게되고
          linux kernel 입장에서는 총 entries는 512개가 되고 커버하는 page크기는 2M가 된다.
          mmu 입장: 1K, 256 entries, 1M memory cover
          kernel 입장: 4K, 512 enties, 2M memory cover
    PGD : 4096개의 entries가 필요하고 이에 대한 크기는 4096 * 4bytes = 16K가 된다.
          하지만 linux kernel 입장에서는 하나의 PTE는 512개의 entries를 가지게 되고, 결국
          2048개만 필요하게 된다.
          mmu 입장: 16K, 4096 enties, 4G memory cover
          kernel 입장: 16K, 2048 enties, 4G memory cover

------------------------------------------------------------
[2014.02.22] 후반
start_kernel() - init/main.c 
1. 아래와 같은 함수들을 살펴 봄
	mm_init_owner() - kernel/fork.c // init_mm의 owner를 init_task로 함
	mm_init_cpumask() - include/linux/mm_types.h
	setup_command_line() - init/main.c // p.265 참조
	setup_nr_cpu_ids()
2. per_cpu에 대하여 공부함.
    - per_cpu는 언제 사용하는가?
        percpu 의 개념 http://studyfoss.egloos.com/5375570
        percpu 의 사용 http://blog.naver.com/PostView.nhn?blogId=nix102guri&logNo=90098904482
    - thread_safe/ re-entrant 가능한가?
    - thread는 cpu를 옮겨 다니는가?
        work-queue http://studyfoss.egloos.com/5626173

--------------------------------------------------------------------------------
[2014.03.01] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
1.      prepare_page_table() - arch/arm/mm/mmu.c
    - PAGE_OFFSET (가상주소0~3G) 까지 pmd를 clear한다.
    - high memory (가상주소3G + 780M)부터 VMALLOC_START까지 pmd를 clear한다.
        왜 VMALLOC_END가 아닌 VMALLOC_START인지는 잘 모르겠다.
2. 의문 : pmd 및 pte는 가상 주소인가? 물리 주소인가?
        
--------------------------------------------------------------------------------
[2014.03.01] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
	    pcpu_embed_first_chunk() - mm/percpu.c
	        pcpu_build_alloc_info() - mm/percpu.c
1. cpu를 group으로 나눈후 각 그룹에 적용했을 때 낭비가 적은 unit per allocs를
    찾는다. alloc과 unit의 상관관계를 알기가 어려워 헤매었다. 다음시간에 마저하도록한다.
    참조 : http://studyfoss.egloos.com/5377666

--------------------------------------------------------------------------------
[2014.03.08] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
        low-mem, dma, device, highmem 영역에 대해 mapping을한다.
        create_mapping() 구현 부분은 너무 복잡해서 책을 참조(p.211)하기로 하고
        넘어간다.

1.      map_lowmem() - arch/arm/mm/mmu.c
	    lowmem 영역에 대해 pgd, pud, pmd, pte를 설정한다.
2.      dma_contiguous_remap() - arch/arm/mm/mda-mapping.c
        dma 영역에 대해 다시 mapping
3.      devicemaps_init(mdesc) - arch/arm/mm/mmu.c
        각 장치에 대해 mapping, gap을 메꾸고, pci를 static_vmlist에 등록한다.
	    mapping 끝부분에 있는 pci_reserve_io()는
        PCI 영역을 static_vmlist에 추가하는 함수이다.
	    vmalloc에서 중요한 구조체는 struct vm_struct 와 struct static_vm가
        있는데, staic_vm은 staic_vmlist의 node고 그것들이 각 vm_struct를
        list로 들고 있다.
        io에 의한 pmd_gap을 메꿔주는 자료는 iamroot에 있다. 링크 필요.
4.      kmap_init() - arch/arm/mm/mmu.c
        p.215 TODO  왜 하나의 PMD가 필요한지 잘 모르겠다.
5.      kmemleak.c에는 kernel에서 메모리 누수 및 디버깅 검출을 위한 함수들이 있다.
        kmemleack 호출 위치 수정요망
--------------------------------------------------------------------------------
[2014.03.08] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
1.      pcpu_embed_first_chunk() - mm/percpu.c
        percpu를 위한 first chuck를 만든후 각 percpu offset을 기록한다.
        자세한 내부 루틴은 다음을 참조한다.
        http://studyfoss.egloos.com/viewer/5377666
2.      smp_prepare_boot_cpu() - arch/arm/kernel/smp.c
        booting cpu의 per_cpu offet을 기록한다.
3.      build_all_zonelists() - mm/page_alloc.c
	    set_zonelist_order()를 호출하여 zonelist의 order를 결정한다.
        zone별로 혹은 node별로...

--------------------------------------------------------------------------------
[2014.03.22] 
start_kernel() - init/main.c
	build_all_zonelists() end 
1. mminit_verify_zonelist() //zonelist 검증.
2. cpuset_init_current_mems_allowed() //mems_allowd 비트맵에 시스템의 모든 노드를 set함.
3. nr_free_pagecache_pages(); //@@ highmem에서 이동 가능한 프리페이지수를 구함.
4. @@ mobility를 할만큼 충분한 가용 페이지가 없으면 mirgration을 하지 않겠다.
 

--------------------------------------------------------------------------------
[2014.03.28]
start_kenrel() - page_alloc_init()

1. hotcpu_notifier()
	- notifier_block 구조체 타입의 page_alloc_cpu_notify_nb를 만들고 우선순위를 0으로 page_alloc_cpu_notify_nb에 등록

	.page_alloc_cpu_notify()
		.lru_add_drain_cpu(cpu)
			TODO: LRU에 대해서

		.drain_page(cpu) - 2014.4.5 시작..


--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
[2014.04.05]
start_kenrel() - page_alloc_init()

[앞시간]
1. lwn: control groups 관련 article reading
        (cgroup의 과거와 현재 그리고 미래)

[뒷시간]
1. understanding linux virtual memory management Chapter.10 Reading: LRU
page replacement policy and Pagecache
2. lru_add_drain_cpu 복습: lru_add_pvec, lru_rotate_pvecs,
lru_deactivate_pvecs 등의 의미와 Pagecache와의 관계
1. drain_page() 하던 중 종료 (2014.04.12 부터 다시)

--------------------------------------------------------------------------------
[2014.04.12]
understanding the linux virtual memory manager
Chapter 2 - Describing Physical Memory
책에서는 각 bank는 node라 불리고 노드를 나타내는 자료 구조는
struct pglist_data {} pg_data_t 이다.
NUMA의 경우 pg_data_t의 list인 pgdat_list로 나타내며, 
UMA의 경우 contig_page_data로 되어있다.
ZONE에 대한 설명은 생략하고, 34Page를 보면 각 구조체의 관계가 나와있다.
pg_data_t -> node_zones -> ZONE_XXX -> node_mem_map(책에는 zone_mem_map으로 나와있음) -> page

Chapter 2.1 Nodes
pg_data_t에 대하여 설명하고 있는데, 책을 참조하고
node_start_paddr은 node_start_pfn으로 변경된듯하고,
node start mapnr은 사라진듯하고, 다음 node를 가리키는
중요한 데이터인 node_next가 사라졌다. 이 부분에 대한 변경이 
현재 코드에 사라진 pgdat_list와 관련이 있는것 같다. (pgdat_list와 pg_list_data랑 혼동하지 말것)

--------------------------------------------------------------------------------
[2014.04.19]
Chapter 2.2 Zones
zone_struct가 zone으로 바뀐듯하다.

2.2.1 Zone Watermarks
zone watermarks는 메모리가 모자를 때 pageout damenon인 kswapd을 언제 깨우느냐에 대한
수위이다.
enum zone_watermarks {
	WMARK_MIN, // free_area_init_core()에서 초기화 되며, direct_recalim path로 극심하게 메모리가 모자른 수위
	WMARK_LOW, // kswapd 이 깨어나서 freeing을 하기 시작하는 수위. 보통 min의 두배
	WMARK_HIGH, // kswapd 이 잠드는 수위. 보통 min의 3배
	NR_WMARK
};

2.2.2 Calculating the Size of Zones
책에서는 setup_memory()에서 각종 min_low_pfn, max_low_pfn, max_pfn을 계산한다고
나왔는데, setup_memory 함수는 없어진듯하다. 대신에 arch/arm/mm/init.c에 bootmem_init을
보면 find_limits로 찾는다.
min_low_pfn은 kernel image 다음의 첫 페이지
max_low_pfn은 ZONE_NORMAL의 끝부분 (kernel/userspace를 나누는 PAGE_OFFSET과도 관련이 있다.)
max_pfn은 적은memory machine에서는 max_low_pfn과 같다. 그럼 큰 메모리에서는?
그리고 위의 세 값은 high memory 위치를 계산하기 위해 바로 넘겨진다.

2.2.3 Zone Wait Queue Table
page를 이용하려는 process들은 wait queue에 들어가게 되는데, page마다
운영하는 것은 공간을 너무 많이 차지한다. 그래서 zone에 wait_table을 만들고
한꺼번에 관리하는데 하나의 큐를 사용하면 unlock시 모든 process가 깨어나는
(thundering heard) 문제가 발생한다.
그래서 hash table을 만들고 page들을 몇개씩(아마도 256개=PAGE_PER_WAITQUEUE?) 모아서
wait queue를 관리한다. hash collision이 발생하면 같은 hash index에 있는 process들이 모두
깨어 나긴 하지만 그래도 공간을 절약하는것이 더 낫다.
자세한 설명은 책과 include/linux/mmzone.h의 zone struct의 wait_table 멤버 설명에 나와있다.
그리고 책에서는 free_area_init_core() 에서 한다고 했는데
mm/page_alloc.c 를 보면 zone_wait_table_init() 함수에서 zone->wait_table을 계산한다.
책에 보면 wait_queue_siz를 계산하는 부분이 나오는데 log2를 하고 있어서 좀 이상하다.

2.3 Zone Initialization
paging_init()
UMA: free_area_init() -> free_area_init_node(0) -> free_area_init_core()
NUMA: free_area_init_node(0) -> free_area_init_core()

2.4 Initializing mem_map
UMA: global mem_map은 pglist_data(0)의(실제로는 contig_pgdat) 의 node_mem_map과 동일하며
alloc_node_mem_map() 함수에서 할당 받는다.
NUMA: global mem_map은 PAGE_OFFSET을 가리키고 그 virtual array 안에
pg_dat의 node_mem_map가 가리키는 page들의 주소가 저장되어 있다.
현재는 없어진 zone 안의 zone_mem_map이 가리키는 주소 또한 virtual array 안에 저장되어 있다.

ex)
UMA: 실제 map 주소 (0x12345678), global mem_map(0x12345678), node_mem_map(0x12345678)
NUMA: 0번 노드의 map 주소 (0x12345678), global mem_map(PAGE_OFFSET), PAGE_OFFSET[XX](0x12345678)
=> 확실치가 않다.

--------------------------------------------------------------------------------
[2014.04.26]
Chapter 2.5. Pages
struct page 에 대한 설명
모든 물리적 페이지 프레임은 struct page 로 관리됨
페이지의 status 를 추적하기 위해서

[list]
list_head 가 page 를 list로 관리함.
2.xv설명) clean_pages list, dirt_pages list, locked_pages 리스트가
존재함.
3.xv) 지금은 확실하지 않다.

[address_space* mapping]
memory mapped -> address space 가리킴.
1. 파일인경우: 파일 조작 address_space
2. anonymous & mapping is setted: swap address space

[unsigned long index]
1. 파일인 경우: 파일의 offset
2. swap_space: space address space offset
3. being freed: order of the block being freed -> stored in index -> 3.x
v에서는 이것이 void* freelist로 관리됨(3.x에서는 union을 이용한다.)

[next_hash]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[count]

[flags]

[lru]

[pprev_has]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[buffers]
-> 3.x에서 buffer_head 사용에 관한 논의(bio를 씀?) (3.x v에서 확인 못함)
ref) http://blog.naver.com/kkn2988?Redirect=Log&logNo=141569528

[virtual]
void* virtual: 커널 메모리 영역(3~4GB)에서 ZONE_NORMAL까지는 direct mapping
되지만, kernel space에서 할당하는 ZONE_HIGHMEM영역은 kmap()으로 매핑된다.
이 kmap()으로 관리되는 영역을 virtual이 가리킴.

Pageflag
-- include/linux/page-flags.h 에서 확인 가능

Chapter 2.6. Mapping Pages to Zones
1. 2.4에서는 struct page마다 zone을 가리키는 포인터가 있었지만 2.6
이후로 삭제되고, 대신 SHIFT를 이용해서 접근함. zone을 위해서 pageflag의
일부 공간을 이용한다.
2. zone_table 의 자료 구조가 있는가? 3.x에서 아직 못찾았음.

Chapter 2.7. High Memory
32bit machine에서 4GB이상의 물리 메모리를 사용하기 위한 PAE등에 대한 설명

Chapter 2.8. What's New in 2.6
1. Zones 자료구조에 업데이트 된 부분들
: zone->lock, zone->lru_lock, zone->pageset과 같이 spinlock contention이 높은
자료구조들을 서로 다른 cacheline에 배치시키기 위해 zone 내부에 padding을 두는
trick을 사용함. (3.9 Level 1 CPU Cache Management 참조)

2. per_cpu_page 자료구조에 대한 의문점들을 아직 가지고 있다.

3. page_state 자료구조는 3.x에서는 사라진 것으로 보인다.

Chapter 3. Page Table Management

pgd_t datatype:
./arch/arm/include/asm/page.h 의 149부터 153번째 줄 참고(3단계인지
2단계인지 아직 명확하지 않음)

unsigned integer 를 structure로 define한 이유? :잘못된 사용을 막기 위해 +
PAE의 4bit를 위해: page granularity때문에 32bit모두 다 필요하지는
않다.((다시 확인해야함)

page granularity 만큼의 remaining bits는 다양한 용도로 사용(PAE 확장,
protection 등등)

--------------------------------------------------------------------------------
[2014.05.10]

Chapter 3. Page Table Management

3.1. Describing the Page Directory
-- 복습
-- Target architecture: 2-level pagetable(11-9-12bits)
-- Why different with x86? (10-10-12bits)
-- Find the references
3.2. Describing a Page Table Entry
-- protection bits usually stored in lower bits (also should find the reference)
-- Arm page protection define (./arch/arm/include/asm/pgtable.h)
-- 1. Hardware page table protection (./arch/arm/include/asm/pgtable-*level-hwdef.h ?)
-- 2. Linux page table protection
-- 차이점에 대해서 알아야 함.
3.3. Using Page Table Entries
-- pmd_bad(), pgd_bad() : we will figure out later
-- page table walk example: follow_page() -> 3.x에서 follow_page_mask()로 바뀜
3.4. Translating and Setting Page Table Entries
-- mk_pte, mk_pte_phys
-- 설명이 너무 간단해서 이해할 수 없다.
-- pfn_to_page, page_to_pfn macros: ./include/asm-generic/memory_model.h 참고
3.5. Allocating and Freeing Page Tables
-- quicklists: pages tables are cached(free가 되더라도 다시 allocation될 수 있으니, cache를 해놓는다)
-- 하지만 quicklists datastructure와 get_pgd_fast()등의 function들을 실제로 사용하고 있는 것은 확인하지 못했음
-- microblaze를 비롯한 일부 architecture dependent code에는 존재하는 것을 확인
3.6. Kernel Page Tables
--3.6.1. Bootstrapping
----8MB memory for Bootstrapping
----pg0 and pg1 point to that space
--3.6.2. Finalizing
---- x86 paging_init (page table 구성) 설명
---- paging_init() for x86: ./arch/x86/mm/init_32.c
---- paging_init() for arm: ./arch/arm/mm/mmu.c
---- paging_init() for x86
------ pagetable_init()
------ kmap_init()
------ zone_sizes_init()
3.7. Mapping Addresses to a struct page
--3.7.1. Mapping Physical to Virtual Kernel Addresses
--3.7.2. Mapping struct pages to Physical Addresses
----struct page 와 physical&virtual address translation에 대해서 다음주에 다시 보기
----swapper_pg_dir : for highmemory?
----VA 3~4GB에 해당하는 kernel memory는 offset +- 로 translation이 가능하고,
----그 이외에는 page table (pgd: swapper_pg_dir)을 이용할 것으로 생각중

--------------------------------------------------------------------------------
[2014.05.17]

3.8 Translation Lookaside Buffer (TLB)
PTE를 이용하여 매번 virtual address를 physical address로 바꾸기
힘드므로 associative memory에 저장하여 놓는다.

TLB의 구조(2way의 경우)
Index | Tag | PPN | valid | Tag | PPN | valid
index는 virtual address의 LSBs
Tag는 virtual address의 나머지 상위 비트
PPN Physcial Page Number
(way와 index의 크기는 2 dimension이며 trade off가 있다.?)

void flush_tlb_all(void) - 전체용
void flush_tlb_mm - context switch용
void flush_tlb_range - 부분용
void flush_tlb_page - page 단위 (가장 작은 단위)
void flush_tlb_pgtables - 특정 플랫폼에서는 pgtables 통채로 entry를 채운다.(?)
void update_mmu_cache - page fault 가 완료되었을 때 호출

Documentation/cachetlb.txt 참조
arm 쪽은 arch/arm/include/asm/tlbflush.h

3.9 Level 1 CPU Cache Management
Level 1과 2 cache가 보통 있는데 linux는 L1 cache만 신경쓴다.
L1_CACHE_BYTES = 2<<5 (1 line의 size)

cache의 종류
direct mapping = 1 way set associate mapping
full associate mapping = max way set associate mapping
set associate mapping = n way set associate mapping
용어
| tag | set(index) | offset |
tag : unique를 보장해주는 MSB
set : index, line을 나타내는 LSB
offset : 한 line 내에서의 offset
n-way : 같은 index를 가진 tag가 n개가 존재한다.

아래의 자료 참조
http://pds12.egloos.com/pds/200809/23/87/hardware_cache_schematic.pdf
민홍교수 ppt

cache를 잘 사용하기 위한 방법
1. 구조체에 자주 사용하는 field는 32bytes 안에 포함되게 앞부분으로 옮겨라
2. false sharing인 되지 않도록 cpus사이에서 사용하는 관계없는 데이터는 떨어 트려라
3. mm_struct 같은 경우는 false sharing을 피하기 위해 32byts align 되어 있다.
* false sharing
http://doriyun.tistory.com/18

* PIPT, VIPT, VIVT에 대한 정보(TLB를 비롯한 주소 변환 유닛들의 위치에 따라 달라짐)
VIPT의 경우 address 하위 12bits의 경우 physical이나 virtual이나
같기 때문에 이 하위 12bits를 이용하여 cache index(set)을 먼저 검출하는것이
가능하기 때문이 아닐지 추축해봄.
http://micol.tistory.com/m/post/257

3.10 What's New in 2.6
1. MMU-less Architecture 지원
mm/nommu.c

2. Reverse Mapping
Page에서는 그것을 이용하는 PTE를 알수가 없다. 이는 swap out할 때
shared page등을 검사할 경우 많은 비용을 수반하게 된다.
이를 위해서 page에서 이를 사용하고 있는 pte들을 가리키는
구조를 만들었다. union pte 이는 단일 pte를 가리킬수도 있고(대부분은 단일 pte이므로),
pte_chain이 될 수도 있다.
mm/rmap.c 가 관계가 있는지 다음 시간에 확인

--------------------------------------------------------------------------------
[2014.05.24]
* Reverse Mapping
- pte_chain에 관한 흔적은 예전 커널의 mm/rmap.c에서 볼수 있으나
현재는 찾을수 없었다.
rmap.c와 reverse mapping이 같은 것인지 잘 모르겠다.
include/linux/rmap.h , mm/rmap.c

* Object-Based Reverse Mapping
모든 page에 대해 reverse map을 유지하는 것은 비용이 많이 필요하므로
VMA(Virtual Memory Area)를 이용하여 관리한다.
VMA는 쉽게 생각하여 page의 시작과 끝을 나타내는 구조체이다.
아래 링크의 그림을 참조하면 쉽게 알수 있다.
kernel memory 구조에 대한 블로그.(How the kernel Manages Your Memory)
http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/

모든 pte를 찾아보려면 두가지 일이 필요한데,
하나는 page_referenced() (어느 페이지가 최근에 참조되었는지 알아보는 함수)
나머지 하나는 try_to_unmap이다.
page에 address_space *mapping 이란 필드가 있는데 이 부분이
reverse mapping이며 두가지 종류로 나뉜다.
하나는 backed file/device 이며, 하나는 anonymous 이다.
file/device의 경우 address_space라고 부르며,
anonymous는 swapper_space라고 부른다.

* kernel : page->mapping(address_space)->i_mmap -> 각 mm_struct들의 vma들의 rbtree
* process : mm_struct->mmap(vma의 list)

try_to_unmap_obj() 설명을 보면 여러 개의 프로세스가 많은 vma를 필요로 하는
하나의 파일을 열고 있을 때에는 object based reverse mapping보다
page based reverse mapping이 더 좋다고 설명하고 ㅣㅇ는데, 이는 앞 단락에 나온 pte_chain이
나오는 reverse mapping이 아닌가 추측되며, 현재는 없어진 것이 아닌가 추측된다.

object based reverse mapping에 관한 자료
https://www.kernel.org/doc/ols/2004/ols2004v2-pages-71-74.pdf

* PTEs in High Memory
PTE를 high memory에 위치 시킬 수 있다. 하지만 그만큼 병목이 될 수 있다.
pte_alloc_kernel()은 kernel PTE 용이고
pte_alloc_map() 은 userspace mapping용이다.
CPU당 하나의 PTE만 high memory를 이용할 수 있다고 하였는데, 그 이유는 모르겠다.

* Huge TLB Filesystem
linux는 전통적으로 kernel image만 4M page를 사용하였다.
HugePage를 이용하면 TLB slot에 큰 이득이 된다.
process가 hugepage를 두가지 방법으로 이용할 수 있다.

shmget() - shared region backed by huge page를 생성할 때 사용.
예를 들어 hugetlbfs에서 new file을
여러개 만든다고 할 때, 각자의 이름은 구분되어야 하고 이는 hugetlbfs_counter에
기록해야 한다. 이런것들에 대한 정보를 저장할 때 이용할 수 있다.
System V에서 넘어온 함수

mmap() - file open huge page filesystem
실제 파일을 open할 때 사용.
file이 open될 때 호출되는 함수. POSIX
만약 MAP_SHARED 옵션으로 호출한다면, shmget()과 비슷한 효과를 나타낸다.

자세한 사항은 Documentation/vm/hugetlbpage.txt 참조

* Cache Flush Management
flush_page_to_ram() 삭제
flush_dcache_range() 추가

--------------------------------------------------------------------------------
[2014.05.31]

Chapter 4. Process Address Space

Abstract
kernel 영역과 user 영역은 주소공간 관리가 다르다.
(예를 들어, kernel 에서 메모리 할당은 어떤 user task 인지 상관없이 globally visible 하기 때문이다.)
하지만 vmalloc은 Page table managemnt 가 필요하기 때문에 추가적인 오버헤드가 필요하다
(vmalloc 은 예외라고 볼 수 있다.)

4.1. Linear Address Space
커널 이미지를 위해 8mb 를 page offset 기준으로 예약한다.
(kernel image를 위해 페이지 테이블을 미리 초기화한다)

kernel address space 
vmalloc_reserved -> highmemory system 에서 최소 128mb를 예약함.
lowmemory system 에서는 더 커질수 있다. 1G - physical memory size 만큼
추가 설명은 7장 history 참조 

4.2. Managing the Address Space
vm_area_struct에 대한 설명 다시함.
System call lists : { fork, clone, mmap, mremap, munmap, shmat, shmdt, execve, exit }

4.3. Process Address Space Descriptor
kernel threads는 mm_struct가 필요하지 않다.
(vmalloc은 예외)
kernel threads는 메모리에 direct mapping 되어 있기 때문.

context switch 할 때 TLB flush overhead를 줄이기 위해서
active_mm을 함께 가지고 있음.(struct task_struct 참고)

mm_users (2로 초기화 됨)
mm_counters (1로 초기화 됨)

mm_users를 감소시킨 뒤에 mm_counters를 감소시키고,
0이 되면 mm_struct를 최종적으로 제거한다.

4.3.1. Allocating a Descriptor
4.3.2. Initializing a Descriptor
4.3.3. Destroying a Descriptor
--------------------------------------------------------------------------------
[2014.06.07]

4.4 Memory Regions
프로세스의 모든 주소공간은 거의  사용되지 않는다. 각각의  공간은 vm_area_struct에 의해 region으로 표현된다.
56페이지 그림 4.2 참조.
ex)
  region이 file과 연결된 메모리를 가지는 경우(backed by a file)의 경우
		 vm_area_struct -> vm_file -> inode -> address_space로 연결.

vm_area_struct 	: ./include/linux/mm_type.h
vm_flags 				: ./include/liinx/mm.h

4.4.1 Memory Region Operations
three operations : open, close, nopage.
	open, close : Resion이 생성되거나 제거될때 사용.
	nopage			: page fault가 발생할때 호출.
								vm_operation_struct -> gernric_file_vm_ops->nopage->filemap_nopage.

4.4.2 File/Device-Backed Memory Regions
address_space : inode->i_mapping과 page->mapping이 address_space를 가르키고 있다.
memory manager는 flush정보가 필요한데 a_ops를 통해서 정보를 알 수 있다.

vm_area_struct : 가상 주소 영역
address_space  : 물리 주소 영역(?)

address_space_operations : include/linux/fs.h
	실제 page를 다루는 함수들.

4.4.3 Creating a Memory Region
system call mmap() dl 프로세스 내에서 새로운 메모리 영역을 생성하도록 한다.
sys_mmap2()->do_mmap2()->do_mmap_pgoff() 로 호출시 파라메터 전달.
그림 4.3 참조. sys mmap2()
do_mmap2():   mmap() 호출시 linux에서 사용하지 않는 MAP_DENYWRITE 와 MAP_EECUTABLE 비트를 제거하고 파일에 맵핑될 경우 세마포어를 획득한다.
do_mmap_pageoff() : sanity check를 하고 파일이나 디바이스가 맵핑된경우 매핑된 사이즈가 페이지 얼라인 된지 확인하고 address space의 커널영역에 생성되지 않도록 한다.
1. 파라미터에 대한 sanity check를 한다.
2. 충분한 선형 주소 공간을 찾는다. get_unmmaped_area()->arch_get_unmmaped_area()
3. VM flage 계산하고 파일 접근 권한에 대해서 체크.
4. 매핑을 원하는 공간에 기존에 매핑된 역역이 있으면 새로운 매핑에 적합하게 기존 공간을 고친다.
5. slab 할당자로부터 vm_area_struct를 할당하고 해당 정보들을 채운다.
6. 새로은 VMA를 연결한다.
7. 파일시스템이나 디바이스에 맞는 mmap 함수를 호출한다.
8. update statistics and exit

4.4.4  Finding a Mapped Memory Region
find_vma()
mmap_cache field 체크. 마지막에 호출된 find_vma()의 결과를 가지고 있음.
만약에 요청한 영역이 아니면 mm_rb 필드에 저장된 red-black 트리에서 찾는다. 만약에 요구된 영역이 어떤 VMA에도 포함되지 않으면 이 함수는 요구된 영역과 가장 가까운 VMA를 리턴한다.
find_vma_prev() : find_vma와 동일하지만 이전 VMA의 위치도 리턴한다.
find_vma_intersection() : 요구된 주용소공관과  겹치는 VMA를 찾기 위해 사용.
vma_merge() : VMA 확장에 사용. VMA가 앞쪽으로 확장할수 없으면 뒤로 확장한다.
get_unmapped_area() 충분한 공간을 찾기위해 사용.

4.4.5 Finding a Free Memory Region
 get_unmmapped_area -> arch_get_unmapped_area(or generic version in mm/mmap.c) -> find_vma

4.4.6 Inserting a Memory Region.
메모리 영역 추가는 insert_vm_struct()을 사용.
이것은 VMAs 사이에 적당한 VMA를 찾기위해 find_vma_prepare() 를 호출하고 
새로운 VMA의 연결을 위해 vma_link를 호출한다.
insert_vm_struct()는 map_count field가 증가하지 않기때문에 잘 사용되지 않고 
map_count를 증가시켜주는 __insert_vm_struct()를 사용한다.

insert_vm_stuct()함수를 사용하지 않고 find_vma_prepare()를 호출한 후  vma_link()를 호출한다. 시간을 줄이기 위해.

4.4.7 Merging Contiguous Regions
merge_segments()대신에 vma_merge()를 사용.
vma_merge()는 sys_mmap(), do_brk()에서 사용된다.
함수를 사용하지 않아도 합쳐지는 경우가 있는데
첫번째는 sys_mprotect()가 호출된경우, mprotect()로 permission이 변경된경우 인접한 영역은 합쳐진다.
두번째는 move_vma()가 호출된 경우, 옆에 위치한 동일할 영역이 합쳐짐
 brk() : http://www.nxmnpg.com/ko/2/brk

4.4.8 Remapping and Moving a Memory Region.
mremap()->sys_mremap()-.do_mremap()->get_unmapped_area()
메모리 영역을 이동하기위해서 충분한 공간을 찾는다.
충분한 공간이 있으면 move_vma()를 호출.
move_vma()는 인접한 VMA들 에 합쳐질 수 있는지 체크하고 
그렇지 않으면 새로운 VMA가 하나의 PTE에 할당한다. 
그리고 move_page_tables()를 호출한다.

이때 사용되는 zap_page_range()의 경우 실제로 페이지를 복사하거나 옮기는것이 아닌
swap out만을 시키고 나중에 page fault handling 코드를 이용하여 다시 swap 한다.

 4.4.9 Locking a Memory Region
mlock()->sys_mlock()을 이용해서 pages(region)를 lock 할수 있다.

mlockall()->sys_mlockall()

==> do_mlock

메모리 lock의 3가지 제한 사항.
1.VMA가 page aligned되어 있다.
2.프로세스가 ystem admin에 의 해 설정된 RLIMIT_MLOCK의 한계가 있다.
3.각 프로세스는 한번에 물리메로리의 절반만 락을 걸수 있다. root process만 pages를 lock을 할 수 있다.

4.4.10 Unlocking the Region
munlock(), munlockall()
sys_munlock, sys_munlockall()
==> 이 함수들은 regions을 수정하기 위해서 do_mmap()에 의존한다.

----------------------------------------------------------------------
[2014.06.14]
4.4.11 Fixing Up Regions After Locking
locking/ unlocking을 할 때, VMA들은 4가지 방버으로 영향을 받는데,
이는 mlock_fixup() 에 의해 수정이 되어야 한다.
mlock_fixup_all(), mlock_fixup_start(), mlock_fixup_end(), mlock_fixup_middle()
흥미로운 점은 locking의 결과로 생성된 VMA들은 lock이 풀리더라도 merge되지 않는다.
- 현재 커널에서는 많이 수정된 듯하다.

4.4.12 Deleting a Memory Region
do_munmap()
  1. red-black tree와 linked list를 수정
    - 만약 부분적인 unmap이라고 할지라도, 일단 삭제하고 unmap_fixed()에서 다시 생성
  2. 관련된 page를 release하고 PTE를 unmapped시킴
    - 이때 PGD를unmap할지라도 PTE를 free하지는 않는다. (비용문제)
  3. 만약 region에 구멍이 생기면 수정함

4.4.13 Deleting All Memory Regions
exit_mmap()을 통해 모든 VMA를 unmap 한다.
그리고 TLB를 flush하고, PTE를 지운다.

4.5 Exception Handling
page fault에 대한 bad reference excetpion만 다루기로 한다.
두 가지 경우가 발생할 수 있는데,
  1. PAGE_OFFSET 이상을 접근할 경우, (4.6?) 잘 이해가 안됨
  2. copy_from_user(), copy_to_user() 의 userspace를 접근하는 함수를 실행할 때 (4.7)
__ex_table이 linker에 의해 생성되며, execution point와 fixup routine으로 구성된다.
exception이 발생시 page fault handler가 manage를 못하면,
search_exception_table()을 호출하고 여기서 대응되는 fixup code의 위치를 찾아서 호출한다.

4.6 Page Faulting
page들이 모두 메모리에 상주할 필요는 없다. 
linux는 Demand Fetch policy르 사용하는데 이는 하드웨어가 page fault exception을
일으키면 backing storage로 부터 fetch되는 것이다.
backing storage의 특성상 prefetch를 이용하면 더 적은 page fault를
일으킬 수 있는데 linux에서는 이 부분에서 좀 원시적이다.
page in될 때 2^ page_cluster만큼 swapin_readahead()만큼 읽어 오지만 불행하게도
곧 사용될 근처의 page들만 읽어오는데 이는 prepaging policy를 형편없게 만든다.

page fault는 major와 minor로 나뉘는데, major page fault는 disk로부터
데이터를 읽어 올때 발생한다. 이것은 아주 비싼 동작이다.
이는 task_struct->maj_flt, task_struct->min_flt에 기록되어 있다.

page fault의 종류
1. Region valid, but page not allocated (Minor)
2. Region not valid but is beside an expandable region like the stack (Minor)
3. Page swapped out, but present in swap cache (Minor)
4. Page swapped out to backing storage (Major)
  - swap-out되어 있으나 pte는 남아 있어, pte를 찾고 disk로 부터 읽어온다.
5. Page write when marked read-only (Minor)
  - COW를 wirte할 때
6. Region is invalid or process has no permissions to access (Error)
7. Fault occurred in the kernel portion address space (Minor)
  - vmalloc area에서 발생할 때, init_mm에의해 현재 process의
    page table들이 master page table에 update 될때. 유일한 kernel page fault
8. Fault occurred in the userpsace region while in kernel mode (Error)

page fault를 처리하는 함수의 이름은 do_page_fault()이고 이는 어러가지 일을 한다. (책 참조)
그중 handle_mm_fault()는 page from backing storage와 COW를 처리한다.

4.6.1 Handling a Page Fault
1. valid한 region인지 검사
2. handle_mm_fault()에서 pmd와 pte가 없을 경우 alloc함
3. pte의 상태에 따라 세가지 경우로 나뉨 (pte bits p.36)
 - 1) pte_present()와 pte_none()을 봄
     - pte_none() - true: 아예 allocation된적이 없다.
                          do_no_page() 호출 -> Demand Allocation(4.6.2 절)
     - pte_none() - false: pte_present()를 체크
     - pte_present() - true: page_fault()가 불릴 이유가 없다.
     - pte_present() - false: alloc된적 있으나 swapped -out되서 내려갔다. 
                              do_swap_page() 호출-> Demand Paging(4.6.3 절)
                              do_no_page()를 호출하는 희귀한 경우가 virtual file일 경우 있음

   2) pte의 write protected인 경우
     do_wp_page()를 호출 - 왜냐면 page가 COW page이기 때문.
     COW page는 여러 포르세스들(부모와 자식)에 의해 공유되는데
     COW page인지 인식 방법은 PTE에서는 모르지만(?) VMA에 writable로 마크(p.63)되어 있기 때문이다.

   3) pte가 이미 read 되어 있고 present인 경우
     3 level page table을 가지지 않은 특정 아키텍쳐에서 발생하는데, young(accessed)으로 마크한다.
     왜 그런지는 다음 시간에...
     
----------------------------------------------------------------------
[2014.06.21]
4.6.2 Demand Allocation
do_no_page() 함수에 의해 수행
vma의 종류는 file/device backed pages와 anonymous pages가 있다.
file/device는 memory-mapped device나 파일로 vm_operations(p.64)이 제공되며
그중 nopage() 함수를 호출한다.

-Handling Anonymous Pages
vm_area_struct->vm_ops 필드가 없거나 nopage() 함수가 없으면,
anonymous page로 분류되며 do_anonymous_page()가 호출된다.
첫 읽기일 경우 write protection이 걸려있는 empty_zero_page로 연결되어 있다.
만약 쓰기 요청이 들어오면 다른 page fault가 발생할 것이다.
ex) kernel source
init/main.c - start_kernel()
    ->arch/arm/kernel/setup.c - setup_arch() 
        ->arch/arm/mm/mmu.c - paging_init()
의 소스를 보면 page table들을 초기화 한 후 empty_zero_page를 만든다.

첫 쓰기일 경우, alloc_page()가 호출이 되고, clear_user_highpage()에 의해
0으로 채워진다. 그리고 mm_struct에 RSS(사용되는 페이지수를 나타냄. p.59)를
하나 증가 시킨다. 특정 아키텍쳐에서는 cache coherency를 높이기 위해 user space
process에 추가 될 때는 flush_page_to_ram()이 호출된다고하는데 잘 모르겠음.
그리고 나중에 재사용(?)을 위해 LRU list에 추가된다.
마지막으로 page table entry가 갱신된다.


-Handling File/Device-Backed Pages
vm_operation 의 nopage()가 제공된다.
file backed 의 경우 filemap_nopage()가 사용되고
virtual file(shmfs)의 경우 shmem_nopage()(ch.12)가 사용되며
각가의 device마다 각각의 nopage()를 제공해야 한다.
valid한 page만 return한다면 내부는 어떻게 만들어졌든 상관이 없다.
page 가 return된 후 체크를 해야 하는데
COW 에 의한 것인지 pte_none()에 의한 것인지에 대해서이다. (자세한 것은 pass)

4.6.3 Demand Paging
backing storage로 swapped out 되어 있을 때 발생하며,
virtual file의 경우는 12장에서 다시 살펴 본다.
shared될 수도 있으니 swapped out이 바로 되지 않고, swap cache에 위치 시킨다.
(RMAP이 생겨서 바뀔 것이르 추측됨)
swap cache에 이미 있을 경우 minor page fault로 reference count만 증가 시키면 되고,
disk에 있을 경우 swapin_readahread()가 호출된다.
low memory machine에서는 보통 2^2, 2^3 page정도이다. (16K ~ 32K)

4.6.4 COW pages
do_wp_page() . 설명은 생략
fork시에 두 프로세스의 pte는 read-only로 되는데
write 요청이 발생하면 PTE write protected되어 있다 할지라도
VMA가 writable이면 이것을 보고 인식하여 do_wp_page()를 수행함

4.7 Copying to/from Userspace
생략

[2014.06.28]
4.8 What's New in 2.6
--Linear Address Space
  vsyscall support 추가. (int 0x80 을 통한 시스템콜이 아니라 userspace page <-> kernel space page 의 매핑을 이용함)
--mm_struct
  free_area_cache (first hole을 알려주는 필드) 를 추가하여 searching time을 절약 
--vm_area_struct
  vm_next_share와 vm_pprev_share 을 shared 필드 하나로 합침
--struct address_space
  gfp_mask field 를 비트 단위로 나누어 두 개의 flags 를 저장한다. (다시 말해, 추가적으로 asynchronous I/O의 상태를 저장하는 flag를 가진다)
  [struct address_space 의 추가적인 필드]
  1. page_tree: linked list -> radix tree 로 변경
  2. page_lock: page_tree 를 보호하는 spin lock
  3. io_pages: do_writepages() 호출하기 전에 메모리의 io_pages list 에 임시 저장
  4. dirtied_when: jiffies 저장
  5. backing_dev_info
  6. private_list: buffer_head를 가리킨다.
  7. private_lock: private_list를 share하는 address_space 간의 private_list를 보호한다.
  8. assoc_mapping
  9. truncate_count
  [struct address_space_operations 의 operations]
  1. writepage:
  2. writepages:
  3. set_page_dirty:
  4. readpages:
  5. bmap:
  6. invalidatepage:
  7. direct_I/O:
--Memory Regions
security module 과 vm area 계정 관리 추가
--4GiB/4GiB User/Kernel Split
1gb 의 kernel 영역은 메모리 사이즈가 커지면, 부족할 수 있다 (mem_map 때문) 이를 해결하기 위한 patch가 있지만 아직 mainstream은 아니다.
--Nonlinear VMA Population
----생략

----------------------------------------------------------------------
Chapter 5. Boot Memory Allocator
Boot Memory Allocator (First Fit style allocator)
--5.1. Representing the Boot Map
  struct boomem_data (Boot memory allocator) 에 대한 설명
--5.2. Initializing the Boot Memory Allocator
--5.3. Initializing bootmem_data
  UMA, NUMA 에서 bootmem_data 초기화
  처음에 bitmap의 bit들을 모두 1로(사용중) 초기화하고, 0(free)으로 바꾸는건 architecture dependent 코드에서 각각 이루어짐
  free_bootmem()을 통해서 0으로 set함
--5.4. Allocating Memory
  memory allocation이 어떻게 이루어지는지 설명
  goal: preferred starting address (first fit allocation), zone_dma (low function) 은 goal 이 0, zone_normal 은 goal 이 MAX_DMA_ADDRESS가 된다
--5.5. Freeing Memory
  페이지의 4KB 모두 free 가 되면 bitmap의 bit를 0으로 바꿈
--5.6. Retiring the Boot Memory Allocator
  Boot memory 를 해제하고 다음 단계의 memory allocator로 전환하는 과정 (각 architecture는 mem_init()을 통해 위의 과정을 제공해야 함)
  free_all_bootmem(UMA), free_all_bootmem_node(NUMA) 를 이용
  free_all_bootmem_core 에서 비트맵의 비트를 모두 1로(사용하지 않은 페이지도 모두 1(사용중)로 세팅) 세팅하고 그 후에 __free_pages()를 통해서 메모리 해제와 buddy allocator 구성을 함께 한다
  이것을 highmemory 영역에 대해서 같은 과정(1로 세팅 후에 다시 __free_pages())을 수행한다
  __init section 은 system start_up 동안에만 사용되는 코드 영역들로, boot memory 를 해제할 때 boot allocator 데이터 영역 뿐 만 아니라, 코드 영역도(bootstraping code section) 메모리에서 free한다
--5.7. What's New in 2.6
  last_success field 추가: search time 감소를 위해서 free가 되면 free된 위치를 last_success가 가리킨다 (offset은 이전과 같음)
  BITS_PER_LONG: BITS_PER_LONG의 블록이 모두 1인지 검사하고, 아니라면 그 때 각각의 bit를 검사
  NUMA & contiguous architecture: contiguous architectures는 자신의 아키텍쳐만의 init_bootmem() 을 정의할 수 있고, 어떤 아키텍쳐도 각자의 reserve_bootmem()을 정의할 수 있다


----------------------------------------------------------------------
[2014.07.12]

mem_map 초기화 
./init/main.c - setup_arch()
./arch/arm/mm/mmu.c - paging_init()
./arch/arm/mm/init.c - bootmem_init()
                       arm_bootmem_free()
./mm/page_alloc.c - free_area_init_node()
                    alloc_node_mem_map()

kernel to physical (real) hardware memory mapping
커널 영역 (3~4gb) 에서 실제 물리 메모리로 매핑하기 위해서 offset을 빼준다.
우리 architecture 에서는 실제 물리 메모리가 0x40000000 부터 시작하고,
커널 메모리는 0xC0000000 부터 시작한다.
그 커널 메모리에서 0x80000000 을 빼서 실제 물리 메모리와 매핑이 된다.
유저 영역 (0~3gb) 는 pgd 를 이용해서 매핑이 됨.

----------------------------------------------------------------------
[2014.07.19]

mm_init() -> mem_init() 분석 중
mm/page_alloc.c
__free_pages_bootmem -> __free_pages() -> __free_pages_ok() -> free_one_page() 분석 중 마침
다음 시간 virtual memory management 책 6 장 읽고 다시 코드 분석 할 예정

----------------------------------------------------------------------
[2014.07.26]

Virtual Memory Manager. Chapter 6. Physical Memory Allocator

6.1. Managing Free Blocks
  struct free_area:
  map: bitmap [2.4 커널에서만 있음] order 에 따라 비트(맵)의 개수가 달라진다. (order = 9 -> 1개, order = 0 -> 256개, 합은 511개)
  nr_free: 3.x 에서 free page blocks 의 개수를 알려주는 unsigned long data type 있음

6.2. Allocating Pages
  __alloc_page : 3.x 커널에서는 다양한 여러 함수이 있음 (e.g., __alloc_pages_high_priority(..))
  __alloc_pages_nodemask(..): the 'heart' of the zoned buddy allocator
  _alloc_pages 없어짐. 호출과정이 변경됨.

6.3. Free Pages
  2.4 kernel mm/page_alloc.c -> -mask = 1 + ~mask ? (최적화인가?)

6.4. Get Free Page (GFP) Flags
  GFP 플래그들: ./include/linux/mm.h -> ./include/linux/gfp.h (3.x) 로 변경

6.5. Process Flags
6.6. Avoiding Fragmentation
6.7. What's New in 2.6

----------------------------------------------------------------------
[2014.08.02]
Chapter 7 Noncontiguous Memory Allocation
cache와 memory-access-latency 때문에 많은 양의 메모리를 다룰 때는연속적인
실제 메모리 페이지를 사용하려고 한다. 하지만 buddy allocator의
external fragment 때문에 항상 가능하지는 않다. linux는 vmalloc()을 통해서
불연속(nocontigouous)한 물리 메모리를 연속적인 가상메모리로 제공한다.
VMALLOC_START와 VMALLOC_END사이에 그 공간이 예약되어 있는데, 이 부분은
x86의 경우 최소 128MB(VMALLOC_RESERVE)이다. p.54에 있는 그림 참조
만약 1G 이상의 물리 메모리를 가졌다면
    VMALLOC_START는 3G + 896M 가 VMALLOC_START이다. (reservered 128M)
만약 512M의 물리 메모리라면
    VMALLOC_START는 3G + 512 + VMALLOC_OFFSET(8M) 이다. (reserved 512M 근처) 
(VMALLOC_OFFSET이 항상 포함되는지는 잘 모르겠음)

7.1 Describing Virtual Memory Areas
struct vm_struct{} // <linux/vmalloc.h>
위의 구조체를 이용하여 list로 운영되며 adress로 정렬되어 있다.

7.2 Allocating a Noncotiguous Area
vmalloc(), vmalloc_dma(), vmalloc_32()를 이용하여 할당
vmalloc_area_pages()를 위한 master page table은 init_mm->pgd 에 있으며
한 프로세스가 page fault exception을 일으키면 init_mm->pgd를 이용하여
PGD, PMD, PTE를 할당하고 최종적으로 alloc_page()를 호출한다. 그리고 이것을
이용하여 현재 프로세스의 page table을 update한다. (그림 7.3 참조)

7.3 Feeing a Noncontiguous Area
vmalloc_area_pages()의 반대되는 함수로 vmfree_area_pages()가 존재

7.4 What's New in 2.6
map_vm_area() array가 추가. 정확히는 모르겠다.
get_vm_area()와 vmap()도 변화가 있다고 하나 생략

code review
init/main.c - mm_init()
  init/main.c - mem_init()
    arch/arm/mm/init.c - free_unused_memmap() // bank와 bank사이의 사용하지 않는 부분 free. 이유 모름
    mm/bootmem.c - free_all_bootmem()
      mm/bootmem.c - free_all_bootmem_core()
        mm/page_alloc.c - __free_pages_bootmem() // order에 따라 buddy를 이용해 free
          mm/page_alloc.c - __free_pages()
            mm/page_alloc.c - free_hot_cold_page() // order 1일 때 호출되며 lru에 넣거나
                // free_pcppage_bulk를 호출. 다음시간 할 차례
            // free_pages_prepare도 안봄

----------------------------------------------------------------------
[2014.08.16]
              mm/page_alloc.c - free_pcppage_bulk()
                mm/page_alloc.c - __free_one_page()
  buddy를 검사하고 buddy가 free이면 다음 order로 이동.
  합쳐지는 루틴이 끝난후 다음 order까지 검사해 보고
  더 합쳐질 가능성이 있으면 lru를 freepage의 뒤로 넣고
  아니면 앞으로 넣는다.
  CompoundPage는 HugeTLB(HugePage)를 이용할 때 여러 개의
  페이지를 합쳤다는 뜻으로 최근에는 PG_tail과 PG_head로 세분화 되었다.
  page->lru는 무엇인지 잘 모르겠다.

                  mm/page_alloc.c - page_is_buddy()
  buddy가 page가 guard page이면서 order가 같거나
  buddy가 free(PageBuddy()호출)이면서 order가 같을 경우 true이다.

  다음 시간 lru의 정체를 밝혀보자.

----------------------------------------------------------------------
[2014.08.23]

1. mm_init()->mem_init(): 버디 할당자 초기화
코드 분석 완료
2. mm_init()->kmem_cache_init(): 슬랩(슬랩/슬롭/슬럽) 할당자 초기화
코드 분석 시작
3. Understanding Linux Virtual Memory Management 책
챕터. 8. 슬랩할당자 시작: Introduction 까지 읽음

다음 시간:
Understanding Linux Virtual Memory Management 책 읽고(8.1. Cache 부터),
kmem_cache_init() 슬럽 부분 분석하도록 한다.

그리고:
page->lru 는 아직 확인 못함.

----------------------------------------------------------------------
[2014.08.30]
8.1 Caches
/proc/slabinfo 를 하면 cache descriptor 정보가 나온다.

8.1.1 Cache Descriptor
각 object type 별로 cache에 저장될 때 사용할 정보를 만들어 놓는다.
kmem_cache_s 구조체는 kmem_cache로 바뀌었으며
현재 커널에서는 slab 은 include/linux/slab_def.h에
slub은 inlclude/linux/slub_def.h 에
slob은 inlclude/linux/slab.h 저장되어 있다.

8.1.2 Cache Static Flags
CFGS_OFF_SLAB

SLAB_HWCACHE_ALIGN : L1 CPU cache 크기에 align
SLAB_NO_REAP: 메모리가 모자를 때 reap하는데 이때 reap 하지 않도록...

8.1.3 Cache Dynamic Flags
kmem_cache_grow()되면 set되는데, set이 되면 kmem_cache_reap()시에 한번
넘어가게 되서 reap 되지 않는다. 하지만 넘어가면서 clear된다.

8.1.4 Cache Allocation Flags

8.1.5 Cache Coloring
L1_CACHE_BYTES에 맞춰(pentium 2는 32 bytes, 우리 ARM은 64bytes) object가
cache될 때 몇개의 line을 사용하는지를 계산 해 놓는다.
colour 는 추가 offset 개수
colour_off 는 각 offset 크기
100 bytes object는 colour는 3이고 colour_off는 32. (PII 에서.)

8.1.6 Cache Creation

8.1.7 Cache Reaping
kswapd에 의해 메모리가 부족하게 되면 하나의 cache를 선택해
메모리를 줄인다. SLAB_NO_REAP이면 넘어가고, DFLGS_GROWN이면 한번 넘어간다.
선택된 cache는 slabs_free의 절반을 free 시킨다.

8.1.8 Cache Shrinking
per-CPU caches에 있는 모든 object를 삭제한다.
gwrowing하고 있지 않다면 slabs_free에 있는 slab도 삭제한다.

8.1.9 Cache Destroying

8.2 Slabs

8.2.1 Stroing the Slab Descriptor

8.2.2 Slab Creation

8.2.3 Tracking Free Objects

8.2.4 Initializing the kmem_bufctl_t Array

kmem_bufctl_t 는 고정된 사이즈의 array 로, 각 element 는 각 object 의
offset (또는 포인터) 을 가리키게 됨.
각 element 에는 다음 free object 의 index number 를 저장하고 있어서
free object 를 관리한다.
free 변수가 가장 상위의 free element 를 저장하고 있어 stack 처럼 동작
하게 된다.
자세한 내용은 책을 참고.

----------------------------------------------------------------------
[2014.09.13]

8.2.5 Finding the Next Free Object
object 에서 다음 free object 를 찾는 방법 설명.
kmem_bufctl_t[slab_t->free]; // free 는 다음 free object 의
index value 를 가지고 있다.

8.2.6 Updating kmem_bufctl_t
kmem_bufctl_t 의 값을 갱신하는 내용 관련.
kmem_bufctl_t 의 값은 오직 어떤 object 가 free 할 때 변경된다.
element 의 값이 다음의 free object index value 를 가진다.
free 변수는 이 값을 읽어 다음에 사용할 free object 의 index value 를
가지게 된다.

8.2.7 Calculating the Number of Objects on a Slab
slab 을 만들 때, kmem_cache_estimate 에서 얼마나 많은 object 개수가
생기는지, 얼마나 많은 bytes 가 낭비되는지 (cache coloring, fragmentation)
등을 계산한다.

8.2.8 Slab Destroying
slab 을 shrunk 하거나 destroy 할 때와 관련된 내용.
각 object 의 destructor 가 불린다.

8.3 Objects
slab 에서 object 들의 할당 및 해제 과정

8.3.1 Initializing Objects in a Slab
kmem_cache_init_objs(): initializing the objects

8.3.2 Object Allocation
kmem_cache_alloc(): 한 object 할당. slab_partial 먼저 채우고 slab_free 에서 채움.
slab_free 가 없으면, slab 을 더 확장한다.
object 할당은 UP 와 SMP 에서 다르게 동작하는데,
SMP 에서 percpu cache 를 사용한다는 것이 다르다.
이 부분은 8.5 장을 더 읽어보고 자세히 이해하도록 한다.

8.3.3 Object Freeing
kmem_cache_free(): destructor 를 호출하면서 object 를 해제하고 초기화한다.
할당과 마찬가지로 UP 와 SMP 에서 다르게 동작하는데,
역시 SMP 에서 percpu cache 를 사용한다.

8.4 Sizes Cache
자주 사용되는 data structures 뿐 만 아니라, 범용 목적 (그리고 DMA) 을 위해서
2의 멱승의 sizes 를 slab 으로 예약해 놓음 (일반과 DMA 각각)
# cat /proc/slabinfo

8.4.1 kmalloc()
8.4.2 kfree()
kmalloc 및 kfree 는 slab 을 이용하는 메모리 할당/해제 interface 정도로 보면 됨.

< on-cache, off-cache >
on-cache: slab_t, bufctl 이 object 들과 한 페이지에 함께 있는 경우
off-cache: object 들이 slab_t (bufctl) 과 다른 페이지에 떨어져 있는 경우
: object 의 사이즈가 작아서 아주 많은 buf index 가 필요한 경우 off-cache 가 됨.

8.5 Per-CPU Object Cache
Per CPU 마다 object pointer 들의 집합을 가지고 있다.
Per CPU 에서 관리되는 Object Cache 는 CPU 들 사이에서 disjoint 되어 있기 때문에,
spin lock 등을 하지 않아도 된다.
Per CPU object cache 들은 memory pool 처럼 동작한다. (해제 시에 곧바로 destroy 
하지 않고, 나중 할당 시에 이용할 수 있도록 한다.) -> 이 부분은 좀 더 확인이 필요하다.

8.5.1 Describing the Per-CPU Object Cache

8.5.2 Adding/Removing Objects From the Per-CPU Cache

8.5.3 Enabling Per-CPU Caches

8.5.4 Updating Per-CPU Information

8.5.5 Draining a Per-CPU Cache

8.6 Slab Allocator Initialization

8.7 Interfacing With the Buddy Allocator

8.8 What's New in 2.6

----------------------------------------------------------------------
[2014.09.20]
kmem_cache_s 는kmem_cache로 바뀌어 각 slab_def(SLAB), slab.h(SLOB), slub_def 등에 있으며
kmem_list3는 kmem_cache_node로 변경되었다.
cpucache_s는 array_cache로 변경되었다. (mm/slab.c)

array_cache에 대한 설명은 UnderstadingKerenel P.335
Local Caches of Free Slab Objects를 참조
간략히 설명하면 slab으로 부터 하나씩 freed object를 얻어 오기 힘드므로
cache 개념을 이용하여 batchcount 만큼 한번에 가져오고 해제하는 방식으로 동작한다.
avail은 실제 slab object가 들어 있는 array의 index를 나타낸다.
또 추가적인 정보는 다음 링크를 참조한다.
동적 메모리 할당자 : slab, slub, slob - http://studyfoss.egloos.com/viewer/5332580

void __init kmem_cache_init(void)
  책의 cache_cache는 kmem_cache_boot로 변경
  - int __kmem_cache_create (struct kmem_cache *cachep, unsigned long flags) 도중 마침

----------------------------------------------------------------------
[2014.09.27]
cache_cache인 "kmem_cache"를 설정하였고, 이를 slab_caches라는 전역 head에 저장한다.
__kmem_cache_create()는 slab의 size를 결정하고, slab당 들어가는 object 개수,
  gfporder등, kmem_cache 구조체의 값들을 설정한다. 그리고 array_cache 및 node를
  초기화 한다.

그 후 "kmalloc-ac"와 "kmalloc-node"를 실제로 slab으로 만든다.

TODO : kmem_cache 자체의 object allocation은 안해도 되는것인가?

----------------------------------------------------------------------
[2014.10.18]
- RW lock 
http://xucxo.blogspot.kr/2011/03/linux-programming-thread-rw-lock.html
장점: 1 write thread, many reader thread에 유리 
단점: writer가 굶을 수 있다.

- seq lock
장점: reader가 lock이 필요없다. writer가 굶지 않는다.
단점: reader가 틀린 값을 가지고 있을 수 있도고 가정

- RCU
https://app.box.com/shared/x5r7ugx6o6
장점: 변경되는 부분을 copy하여 만들고,
원래 값을 가지고 있던 reader는 그것을 사용. 특히 pointer 구조에 사용

- spin lock

- CAS?

참고 자료
NDC2012 병렬 프로그래밍
http://www.slideshare.net/tatis3/ndc12-12700288

NDC2014 멀티 쓰레드 프로그래밍이 왜이리 힘드나요?
http://www.slideshare.net/zzapuno/kgc2013-3

NDC2014 헤테로지니어스 컴퓨팅 CPU -> GPU
http://www.slideshare.net/zupet/ndc14-gpu


User space: pthread_mutex, pthread_rwlock

================================================================================
2014.10.25
Red Black Tree visualziation
https://www.cs.usfca.edu/~galles/visualization/RedBlack.html

* 리눅스 커널 내부구조 3장
fork(), vfork() -> process 생성, 내부적으로는 do_fork()
pthread_create() -> thread 생성, 내부적으로는 do_fork()
clone() -> 옵션에 따라 둘 다 생성, 내부적으로는 do_fork()

* context switching은 언제 하나?
time-slice를 다 사용하면 누가 그것의 context를 저장하고, 다음 context를
load하는가? timer interrupt?

* signal catch timing
task_struct에서 signal을 설정만 해놓고,
kernel level에서 user level로 돌아오는 타이밍에 실행되는 것이라면
무한루프 프로그램을 돌렸을때 제대로 안 멈추는 것은
system call이 없기에 바로 signal을 catch하지 못하고 다음 time slice를
사용할때 catch 하기 때문 아닐까?
http://www.iamroot.org/xe/QnA/41643

* Scheduler 정책
SCHED_FIFO : 0 ~ 99 -> RT
SCHED_RR   :  0 ~ 99 -> RT
SCHED_NORMAL(OTHER), BATCH, IDLE: 100 ~ 139 -> O(1), CFS
http://www.iamroot.org/xe/QnA/35618

* O(1)
running과 ready 상태에 있는 thread를 표현하는 runqueue 라는 구조체안에
active와 expired가 있는데, 실행후 active에서 expired로 옮긴 후 모두 다
옮기고 나면 active와 expired를 swap 한다.
Q: O(1) 스케줄러가 비선점형 커널의 주요 원인인가?

================================================================================
20141101
code review

================================================================================
20141108
shched_init() 시작
	리눅스 스케쥴러의 변천사 O(1), CFS
		http://enginius.tistory.com/97

	init_defrootdomain():
		1. cpupri를 위해 메모리를 할당 받고 각 cpu별 cpu_to_pri를 CPUPRI_INVALID=-1로 설정.
			cpupri_init :
				 참고)http://code.google.com/p/linuxkernel-iamroot/source/browse/trunk/kernel/sched_cpupri.c?r=60
	init_rt_bandwith()
		1. rt_bandwith의 rt_period, rt_runtime을 초기화
		2. hrtimer( high resolution timer) 초기화    참고)http://studyfoss.egloos.com/viewer/5268468
			 각 cpu별 hrtimer 및  timequeue 초기화	
				.CLOCK_REALTIME (0) : 현재 시간을 기준으로 하여 시간을 계산한다. 시스템 시간 변경 시 영향을 받는다.
				.CLOCK_MONOTONIC (1) : 커널이 동작한 시간을 기준으로 하여 시간을 계산한다. 외부의 영향을 받지 않는다.
			-clock source의 종류
				.RTC(real time clock)
				.PIT(programable interval timer)
				.hpet(high precision event timer)
				.TSC(time stamp counter) : cpu 안에 들어있는 HW counter
			timerqueue_init(&timer->node) : rb_node에 대해서 RB_CLEAR_NODE
		3. hrtimer_forward() : 다음 interval을 위해서 만료 시간을 이 함수가  리턴되기 전에 설정해 둔다. 
				그래야 다음 event시에 만료 시간을 알 수 있다. 
			period 는 interval을 의미.

                    timer                                current time
											& -> forword or advancing           

           -----------7----+------------+-------------+------**------
                         
									ovrrun   1            2             3      ; 현재 overrun 값은 3

참고)professional Linux kernel Architecture(p.925)에서
Let us illustrate the behavior by an example. If the old expiration time is 5, now is 12,
and interval is 2, then the new expiration time will be 13. The return value is 4 because
13 = 5 + 4 × 2.    overrun: 4개 (5, 7, 9, 11) 


The high-resolution timer API
참고) http://lwn.net/Articles/167897/
		리눅스 커널 심층분석, 리눅스 커널의 이해

메모리에서는 주소가 중요하다면, CPU에서는 시간이 중요하다.

================================================================================
2014.11.15

[Group & Scheduling in Linux]
(http://lwn.net/Articles/80911/)
(http://sunjinyang.wordpress.com/2010/10/06/linux-kernel-scheduling-domains-and-classes/)

Scheduling domain(스케줄링 영역): 스케줄링 그룹 자료 구조와 함께 구성되며
계층적인 방식으로 전체 시스템의 영역을 구성한다.
속성(properties)과 정책(policies)를 공유하는 cpu 집합으로, 해당 cpu 간에 부하가 균등하게 조절됨.
스케줄링 영역은 스케줄링 그룹을 한 개 이상 포함하기 때문에 스케줄러가 한 영역 내에서의
균형을 유지하려 할 때 그룹 안에서 발생하는 상황을 걱정하지 않고 그룹의 부하(load)를 다른 그룹으로 이동한다.

Scheduling group: cpu 의 묶음 (하나 또는 그 이상의 cpus), 하이퍼 스레딩이 되는 cpu나,
smp 나 numa 영역 단위 등으로 다양하게 묶일 수 있음. (상황에 따라 다르게 그룹이 될 것이라고 생각하고 있다)

Scheduling class: 코어 스케줄러를 돕는 여러 모듈을 연결해 놓은 고리처럼 볼 수 있다. (정책과 구현의 분리)
각 스케줄러 모듈은 스케줄러 클래스 구조체(struct sched_class 로 존재)가 제안하는 기능을 콜백 함수처럼 구현한다.
(리눅스 코드 참조)

스케줄링 영역은 계층적으로 구성될 수 있다.
예)
하이퍼 스레딩 수준 영역 < 물리적 프로세서 수준 영역 < 누마 노드 수준 영역
하이퍼 스레딩 수준 영역 < 물리적 프로세서 수준 영역 < 프로세서 소켓 (클러스터) 수준 영역 < 누마 노드 수준 영역
등등 가능하다.

각 스케줄링 영역 특성에 맞는 스케줄러 정책 활용이 가능.

================================================================================
2014.11.22

선점형 커널에서 스케줄러 호출 시점.
1. 프로세스가 TASK_RUNNING상태가 되면 현재 실행 중인 프로세스보다 동적
   우선순위가 높다면 current 실행을 중단하고 스케줄러 호출.
2. 프로세스가 주어진 타임퀀텀을 모두 사용했을때 thread_info 자료 구조의
   NEED_RESCHED flag가 설정되며, 타이머 인터럽트 핸들러가 끝날때 호출.

================================================================================
2014.12.13
리눅스 커널 내부 구조.
p.76 스케줄러가 호출 되는 시점
1. 클럭 인터럽트의 서비스 루틴이 종료될 때 현재 수행되고 있는 task의 
need_resched 필드를 살펴보고 호출
2. 새로 생성된 태스크가 선점되야 할 경우
3. 현재 수행되고 있는 태스크가 자신의 타임 슬라이스를 모두 소진한 경우
4. 현재 태스크가 sched_setscheduler() 같은 시스템 콜을 호출할 경우

Documentation/scheduler/sched-arch.txt
Context Switch 시 run queue의 lock과
CPU idle 상태에 대한 규칙이 나타나 있는데, Idle 상태에 대한 지식이 없어
실제적으로 이해하기가 힘들다. 나중에 다시 볼것

Documentation/scheduler/sched-design-CFS.txt
vruntime : nice(priority)에 따른 weight를 반영한 가상의 cpu 사용 시간. 동일한 time slice에 대해
weight가 높을 수록 vruntime은 적게 증가할 것이고, 낮을 수록 vruntime은 빠르게 증가할 것이다.
http://studyfoss.egloos.com/viewer/5326671

timeslice를 0.01이라고 가정
 W0/WP vruntime -->
A(0.1) 0 0.001 0.001           0.002 0.003 0.004 0.004 0.005
B(0.3) 0 0     0.003           0.003 0.003 0.003 0.006 0.006
C(1)   0 0     0.01            0.01  
D(3)   0 0     0     0.03        
E(9)   0 0     0          0.09        
실행순서는 다음과 같을 것이다.
A-B-C-D-E-A-A-A-B-A-A-A...

/proc/sys/kernel/sched_min_granularity_ns
를 보면 schedule 최소 단위가 나오는데 desktop의 경우
1000000 (= 1ms) 정도가 된다. server군의 경우 더 큰 값일 것으로 추정된다.

SCHED_BATCH 또한 CFS 로 운용된다
이런 디자인상 fiftyp.c, thud.c, chew.c, ring-test.c, massive_intr.c과 같은
공격에 강하다고 하는데, 정확히는 모르겠다.

Schedule Class => Stop, RT, Fair, Idle

* CFS Schedule Class의 하부 policy로는
SCHED_NORMAL(SCHED_OTHER)
SCHED_BATCH, 선점당하지 않고 일을 처리하고 가끔 일반 태스크 실행. 상호작용에 비용듬
SCHED_IDLE, nice 19보다 더 약하다고 하는데 정확한 존재이유는 잘 모르겠음

* RT의 하부 policy로는 
SCHED_FIFO
SCHED_RR

100 개의 runqueue가 존재하며(priority갯수 만큼) 이는 예전에 140개에서 CFS가 생긴만큼
줄어든 것이다. 그리고 expired array가 없다고 하는데 추가 확인이 필요하다.
 - enqueue_task : scheduling entity(task)를 rb tree에 넣음. nr_running 증가
 - dequeue_task : rb tree로부터 뺄때 호출됨. nr_running 감소
 - yield_task : 기본적으로 dequeue한 후 enqueue한다. compat_yield일 경우 트리의 맨 오른쪽으로 이동?
 - check_preempt_curr : 지금 running task가 preempt여야 하는지 체크하는 함수
 - pick_next_task : 다음에 run될 task 선택
 - set_curr_task : scheduling class가 변경되거나 task group이 변경될때 호출되는 함수 
 - task_tick : time tick마다 불려지는 함수

CONFIG_CGROUP_SCHED : group scheduling 사용 유무 
- CONFIG_RT_GROUP_SCHED : group scheduling을 RT에 적용
- CONFIG_FAIR_GROUP_SCHED : group scheduling을 FAIR에 적용
Cgroup 설정 예제는 sched-design-CFS.txt 참조 

================================================================================
2014.12.20
----------------
Documentation/scheduler/sched-domains.txt
* sched_domin
 -span (cpu를 포함)
* sched_group
 -groups (모든 group의 합집합은 span)

* load_balance() - 현재 sched domain에서 가장 바쁜group을 찾고, 다시 가장 바쁜 런큐(cpu)를 그 그룹에서
찾는다. 그리고 현재 cpu의 런큐와 찾은 런큐를 모두 락을 걸고, 찾은 가장 바쁜 큐에서 task들을 가져온다.
이동된 task의 양은 이전 sched domain 그룹에서 계산된 값들이다. 

* SMT(hyper thread) -> SMP -> NUMA
physical cpu - core? chip 하나?
* domain 구조 두가지
#define ARCH_HASH_SCHED_TUNE
#define ARCH_HASH_SCHED_DOMAIN

* Big.Little은 AMP인가? 에 대해 궁금해 하다가...
Big.Little, cluster migration, MP(HMP), CPU migration
8core -> 4 core/ 4 core cpu migration
http://gamma0burst.tistory.com/613
결과적으로 H/W는 AMP, S/W는 SMP 처럼 보인다.

----------------
sched-nice-design.txt
* time slice와 hz에 기반해서 nice 가 동작했기 때문에 예전 스케줄러에서 잘 동작하지 않았음
* O(1)에서 기존 2.4에서 보다 - nice값의 기울기를 조정하여 더 강하게 만듬
* nice에 대한 3가지 불만 
 - 1. +19의 경우 1ms 정도가 맞지만 그러면 rescheduling비용이 너무 증가하니 5ms정도로 함. 그랬더니 너무 많은 cpu를 차지함
 - 2. 상대적인 nice 값의 차이가 구간별로 다른 차이를 나타냄
 - 3. 버그 있는 RT가 FIFO로 돌때 뒤의 nice에게는 기회가 안옴

 * 신규 스케줄러
 - 1. Hz와 time slice(jiffy)의 값에 따라 +19가 1초당 차지하는 cpu 점유율이 변하게 되었는데
 이를 time slice와 Hz와 분리하여, +19는 1.5%의 cpu 점유율을 가지도록 함
 - 2. nice의 값 차이에 따라 어느 구간이던 같은 비율을 유지하도록 함
 - 3. FIFO에 비해 강력하지 못할때, 자동적으로 recalibrate하여 nice level을 조정한다.

----------------
 * sched-rt-group.txt
- period : 수행되야 하는 주기
- runtime : 수행 주기동안 차지하는 cpu time
/proc/sys/kernel/sched_rt_period_us: 1000000 (전체 cpu bandwidth)
/proc/sys/kernel/sched_rt_runtime_us: 950000 (최대 rt가 사용할수 있는 시간)

CONFIG_RT_GROUP_SCHED, cgroup으로 group scheduling 사용
현재의 문제점. sibling 끼리의 starvation.
나중에 SCHED_EDF(Earliest Deadline First scheduling)가 나오면 해결되겠지만, 힘들어 보인다.

================================================================================
2015.01.03
----------------
Documentation/scheduler/sched-bwc.txt

SCHED_NORMAL 에서 schedule group 들의 CPU bandwidth 를 제어하는 방법을 설명한다.
각 그룹에게 quota 와 period 를 지정해서 CPU bandwidth 를 지정해 줄 수 있다.
- period (microseconds): 각 period 마다 CPU time 의 quota 만큼의 bandwidth 를 사용.
- quota: schedule group 이 소비할 수 있는 CPU time bandwidth
- runtime: 작업을 하는데 소비된 시간
- unused runtime: 주어진 bandwidth 에서 runtime 을 수행하고 남는 시간
unused runtime 은 global 하게 추적되고 period 마다 초기화된다. 이러한 시간들은
"slice" 로 관리된다.

bandwidth 를 초과하면 throttled 되고 다음 period 가 시작될 때까지 스케줄 되지
않는다. period 가 얼마나 수행되었는지, throttled 가 얼마나 되었는지 등은
통계로 남는다 (read-only).

cfs_quota_us 나 cfs_period_us 들은 cgroupfs 를 통해 지정될 수 있다.
기본값은 period = 100ms, quota = -1 이다.
quota 의 음수 값은 제약사항이 없다는 것을 의미한다.

양수 값을 통해 period 와 quota 를 지정할 수 있지만 (maximum period = 1ms)
cgroup 특성 상 계층적으로 schedule group 이 나뉘어져 있으면 추가적인 제약사항들이
생긴다 (예를 들어, 부모의 quota 에 종속적이다).

기타 다양한 제약 사항을들을 groupfs 들을 통해 관리하며, 이러한 내용들이
documentation 에 설명되어 있다.

----------------
Documentation/scheduler/sched-stats.txt
statistics 관련 문서 분석은 생략한다.

================================================================================
2015.01.10
----------------
sched_init() 코드 분석 계속 중
