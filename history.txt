[2014.01.25] review
arch/arm/kernel/setup.c - setup_arch()

1. 저번 시간의 setup_machine_fdt()에 이어 setup_machine_tags() 함수를 봄
    atags_pointer 정보가 담겨있는 address를 기반으로 fdt인가를 확인한후
    fdt가 아닐 경우 setup_machine_tags를 호출한다.
    우리는 atags를 사용하지 않지만 살펴보면 setup_machine_fdt()와 비슷한 구조를
    가지고 있다. machine_desc들로부터 적당한 machine_desc를 찾아내고, atags 정보를
    저장, parse한다.

2. 그 후 setup_machine_fdt() 혹은 tags()로 부터 boot_coomand_line을 cmd_line에 저장한 후,
3. early_param을 파싱하여 earlycon=, console= 옵션을 얻어낸다.
4. 그리고 memory bank를 address순으로 정렬한다. (atags사용시 의미가 있는지는 잘 모르겠다.)

------------------------------------------------------------
[2014.01.25] normal
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
        arch/arm/mm/init.c - bootmem_init()
            arch/arm/mm/init.c - arm_bootmem_free()
                arch/mm/page_alloc.c - free_area_init_node()
                    arch/mm/page_alloc.c - free_area_init_core()

1.                    arch/mm/page_alloc.c - init_currently_empty_zone()
    해당 함수는 zone의 wait_table과 free_list를 할당하고 초기화하는 함수이다.

2.                    arch/mm/page_alloc.c - memmap_init() = memmap_init_zone()
    해당 함수는 page에 zone, nid, page_count, mapcount 등을 설정.
    중간에 set_pageblock_migratetype이란 함수가 나오는데, pageblock의 개념을 잘 모르겠다.
    sparse에서 use_map(section의 시작 포인터)이 pageblock_flag에 저장되었는데, 이것이 왜
    pageblock인지 이유를 알수 없음. use_map이 pageblock인지 조차 잘 모르겠다. TODO


------------------------------------------------------------
[2014.02.15] review
arch/arm/kernel/setup.c - setup_arch()
1.    arch/arm/mm/mmu.c - sanity_check_meminfo()
    sanity_check_meminfo()함수는 membank를 순환하면서 highmem인지 검출하고,
    겹쳐 있는 부분을 나누며, high_memory, memblock_limit등을 설정한다.
    __pa(vmalloc_min - 1) + 1의 경우 vmalloc_min은 high memory의 시작 위치를
    나타내고(760M = 0xEF800000), __pa 함수는 물리 주소로 변환, -1/+1은 잘못된
    변환을 막기 위해서 사용한다. 자세한 내용은 C팀의 후기를 참조하도록 한다.

    - vmalloc_min과 -1/+1에 대한 설명 
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&page=3&document_srl=185255
    - __pa, __virt_to_phys() 함수에 대한 설명
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905

------------------------------------------------------------
[2014.02.15] 후반
arch/arm/kernel/setup.c - setup_arch()
    arch/arm/mm/mmu.c - paging_init()
1.  paging_init()함수 내부 아랫쪽의 zero_page를 flush시키는 곳부터 시작.
    zero_page는 읽기를 위한 page로서 효율을 위해 만들어진 페이지이며,
    쓰기요청이 들어올경우 COW로 작동한다.
    아랫부분에 __flush_dache_page 함수가 있는데, 왜 flush를 하는지와
    내부 구현은 cache에 대한 이해가 부족에 미루기로 한다.

arch/arm/kernel/setup.c - setup_arch()
2.  request_standard_resources에서 iomem_resource와 iomem_resource tree에
    system ram, kernel code, video ram, lp port등을 할당한다.
3.  unflatten_device_tree로 나머지 device  tree를 완성하고, cpu, psci, smp설정을 한다.
    그중 smp_build_mpidr_hash함수는 pass. reverse_crashkernel을 위한 공간도 만들어서
    iomem_resource에 추가한다.
5.  mdesc->init_early() 는 있을듯한데 없다.

------------------------------------------------------------
[2014.02.22] review
setup_arch() - arch/arm/kernel/setup.c 
1.  arm_memblock_init() - arch/arm/mm/init.c
    meminfo로부터 memblock.memory->region을 만들고,
    kernel text/bss, initrd, swapper_pg_dir, dt내의 reverve영역,
    mdesc->reserve영역, DMB contiguos 부분을 memblock.reserve에 추가한다.
    memblock_add -> memblock_add_region -> memblock_double_array() 부분은 
    어느 부분까지 동작하는지 잘 모르겠으므로 패스한다.
    DT level : bank 정보로 부터 meminfo를 만듬
    memblock level : meminfo로 부터 memblock정보를 region으로 채움

    paging_init() - arch/arm/mm/mmu.c
2.      build_mem_type_table() - arch/arm/mm/mmu.c
    cachepolicy와 memtype을 설정한다. 자세한 사항은 다음을 참조하자.
    http://www.iamroot.org/xe/index.php?mid=Kernel_10_ARM&document_srl=185905
 
3. prepare_page_table -preview
    32 bits를 1,2차 table과 page로 나누면, 31~20(1차)/19~12(2차)/11~0(page size)로 나눠지게 된다.
    그러므로 1차table (PGD)의 entries는 4096개가 되고, 2차 table(PTE)의 entries는 256개가 되며,
    page size는 4K가 된다.
    PTE : 256개의 enties는 1K(256 * 4bytes)의 공간을 차지하게 되는데(이때 커버하는 page크기는 1M)
          ARM의 경우 HW의 entry에 dirty bit같은 부가 정보가
          없으므로 linux용 entry가 따로 필요하게 된다. 그러다 보니 pte가 차지하는 공간은
          2K로 늘어나게 된다.
          거기에 pte의 크기가 page의 크기가 되어야 하기 때문에 2쌍이이 들어갈수 있게되고
          linux kernel 입장에서는 총 entries는 512개가 되고 커버하는 page크기는 2M가 된다.
          mmu 입장: 1K, 256 entries, 1M memory cover
          kernel 입장: 4K, 512 enties, 2M memory cover
    PGD : 4096개의 entries가 필요하고 이에 대한 크기는 4096 * 4bytes = 16K가 된다.
          하지만 linux kernel 입장에서는 하나의 PTE는 512개의 entries를 가지게 되고, 결국
          2048개만 필요하게 된다.
          mmu 입장: 16K, 4096 enties, 4G memory cover
          kernel 입장: 16K, 2048 enties, 4G memory cover

------------------------------------------------------------
[2014.02.22] 후반
start_kernel() - init/main.c 
1. 아래와 같은 함수들을 살펴 봄
	mm_init_owner() - kernel/fork.c // init_mm의 owner를 init_task로 함
	mm_init_cpumask() - include/linux/mm_types.h
	setup_command_line() - init/main.c // p.265 참조
	setup_nr_cpu_ids()
2. per_cpu에 대하여 공부함.
    - per_cpu는 언제 사용하는가?
        percpu 의 개념 http://studyfoss.egloos.com/5375570
        percpu 의 사용 http://blog.naver.com/PostView.nhn?blogId=nix102guri&logNo=90098904482
    - thread_safe/ re-entrant 가능한가?
    - thread는 cpu를 옮겨 다니는가?
        work-queue http://studyfoss.egloos.com/5626173

--------------------------------------------------------------------------------
[2014.03.01] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
1.      prepare_page_table() - arch/arm/mm/mmu.c
    - PAGE_OFFSET (가상주소0~3G) 까지 pmd를 clear한다.
    - high memory (가상주소3G + 780M)부터 VMALLOC_START까지 pmd를 clear한다.
        왜 VMALLOC_END가 아닌 VMALLOC_START인지는 잘 모르겠다.
2. 의문 : pmd 및 pte는 가상 주소인가? 물리 주소인가?
        
--------------------------------------------------------------------------------
[2014.03.01] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
	    pcpu_embed_first_chunk() - mm/percpu.c
	        pcpu_build_alloc_info() - mm/percpu.c
1. cpu를 group으로 나눈후 각 그룹에 적용했을 때 낭비가 적은 unit per allocs를
    찾는다. alloc과 unit의 상관관계를 알기가 어려워 헤매었다. 다음시간에 마저하도록한다.
    참조 : http://studyfoss.egloos.com/5377666

--------------------------------------------------------------------------------
[2014.03.08] review
setup_arch() - arch/arm/kernel/setup.c 
    paging_init - arch/arm/mm/mmu.c
        low-mem, dma, device, highmem 영역에 대해 mapping을한다.
        create_mapping() 구현 부분은 너무 복잡해서 책을 참조(p.211)하기로 하고
        넘어간다.

1.      map_lowmem() - arch/arm/mm/mmu.c
	    lowmem 영역에 대해 pgd, pud, pmd, pte를 설정한다.
2.      dma_contiguous_remap() - arch/arm/mm/mda-mapping.c
        dma 영역에 대해 다시 mapping
3.      devicemaps_init(mdesc) - arch/arm/mm/mmu.c
        각 장치에 대해 mapping, gap을 메꾸고, pci를 static_vmlist에 등록한다.
	    mapping 끝부분에 있는 pci_reserve_io()는
        PCI 영역을 static_vmlist에 추가하는 함수이다.
	    vmalloc에서 중요한 구조체는 struct vm_struct 와 struct static_vm가
        있는데, staic_vm은 staic_vmlist의 node고 그것들이 각 vm_struct를
        list로 들고 있다.
        io에 의한 pmd_gap을 메꿔주는 자료는 iamroot에 있다. 링크 필요.
4.      kmap_init() - arch/arm/mm/mmu.c
        p.215 TODO  왜 하나의 PMD가 필요한지 잘 모르겠다.
5.      kmemleak.c에는 kernel에서 메모리 누수 및 디버깅 검출을 위한 함수들이 있다.
        kmemleack 호출 위치 수정요망
--------------------------------------------------------------------------------
[2014.03.08] 후반
start_kernel() - init/main.c 
	setup_per_cpu_areas() - mm/percpu.c
1.      pcpu_embed_first_chunk() - mm/percpu.c
        percpu를 위한 first chuck를 만든후 각 percpu offset을 기록한다.
        자세한 내부 루틴은 다음을 참조한다.
        http://studyfoss.egloos.com/viewer/5377666
2.      smp_prepare_boot_cpu() - arch/arm/kernel/smp.c
        booting cpu의 per_cpu offet을 기록한다.
3.      build_all_zonelists() - mm/page_alloc.c
	    set_zonelist_order()를 호출하여 zonelist의 order를 결정한다.
        zone별로 혹은 node별로...

--------------------------------------------------------------------------------
[2014.03.22] 
start_kernel() - init/main.c
	build_all_zonelists() end 
1. mminit_verify_zonelist() //zonelist 검증.
2. cpuset_init_current_mems_allowed() //mems_allowd 비트맵에 시스템의 모든 노드를 set함.
3. nr_free_pagecache_pages(); //@@ highmem에서 이동 가능한 프리페이지수를 구함.
4. @@ mobility를 할만큼 충분한 가용 페이지가 없으면 mirgration을 하지 않겠다.
 

--------------------------------------------------------------------------------
[2014.03.28]
start_kenrel() - page_alloc_init()

1. hotcpu_notifier()
	- notifier_block 구조체 타입의 page_alloc_cpu_notify_nb를 만들고 우선순위를 0으로 page_alloc_cpu_notify_nb에 등록

	.page_alloc_cpu_notify()
		.lru_add_drain_cpu(cpu)
			TODO: LRU에 대해서

		.drain_page(cpu) - 2014.4.5 시작..


--------------------------------------------------------------------------------


--------------------------------------------------------------------------------
[2014.04.05]
start_kenrel() - page_alloc_init()

[앞시간]
1. lwn: control groups 관련 article reading
        (cgroup의 과거와 현재 그리고 미래)

[뒷시간]
1. understanding linux virtual memory management Chapter.10 Reading: LRU
page replacement policy and Pagecache
2. lru_add_drain_cpu 복습: lru_add_pvec, lru_rotate_pvecs,
lru_deactivate_pvecs 등의 의미와 Pagecache와의 관계
1. drain_page() 하던 중 종료 (2014.04.12 부터 다시)

--------------------------------------------------------------------------------
[2014.04.12]
understanding the linux virtual memory manager
Chapter 2 - Describing Physical Memory
책에서는 각 bank는 node라 불리고 노드를 나타내는 자료 구조는
struct pglist_data {} pg_data_t 이다.
NUMA의 경우 pg_data_t의 list인 pgdat_list로 나타내며, 
UMA의 경우 contig_page_data로 되어있다.
ZONE에 대한 설명은 생략하고, 34Page를 보면 각 구조체의 관계가 나와있다.
pg_data_t -> node_zones -> ZONE_XXX -> node_mem_map(책에는 zone_mem_map으로 나와있음) -> page

Chapter 2.1 Nodes
pg_data_t에 대하여 설명하고 있는데, 책을 참조하고
node_start_paddr은 node_start_pfn으로 변경된듯하고,
node start mapnr은 사라진듯하고, 다음 node를 가리키는
중요한 데이터인 node_next가 사라졌다. 이 부분에 대한 변경이 
현재 코드에 사라진 pgdat_list와 관련이 있는것 같다. (pgdat_list와 pg_list_data랑 혼동하지 말것)

--------------------------------------------------------------------------------
[2014.04.19]
Chapter 2.2 Zones
zone_struct가 zone으로 바뀐듯하다.

2.2.1 Zone Watermarks
zone watermarks는 메모리가 모자를 때 pageout damenon인 kswapd을 언제 깨우느냐에 대한
수위이다.
enum zone_watermarks {
	WMARK_MIN, // free_area_init_core()에서 초기화 되며, direct_recalim path로 극심하게 메모리가 모자른 수위
	WMARK_LOW, // kswapd 이 깨어나서 freeing을 하기 시작하는 수위. 보통 min의 두배
	WMARK_HIGH, // kswapd 이 잠드는 수위. 보통 min의 3배
	NR_WMARK
};

2.2.2 Calculating the Size of Zones
책에서는 setup_memory()에서 각종 min_low_pfn, max_low_pfn, max_pfn을 계산한다고
나왔는데, setup_memory 함수는 없어진듯하다. 대신에 arch/arm/mm/init.c에 bootmem_init을
보면 find_limits로 찾는다.
min_low_pfn은 kernel image 다음의 첫 페이지
max_low_pfn은 ZONE_NORMAL의 끝부분 (kernel/userspace를 나누는 PAGE_OFFSET과도 관련이 있다.)
max_pfn은 적은memory machine에서는 max_low_pfn과 같다. 그럼 큰 메모리에서는?
그리고 위의 세 값은 high memory 위치를 계산하기 위해 바로 넘겨진다.

2.2.3 Zone Wait Queue Table
page를 이용하려는 process들은 wait queue에 들어가게 되는데, page마다
운영하는 것은 공간을 너무 많이 차지한다. 그래서 zone에 wait_table을 만들고
한꺼번에 관리하는데 하나의 큐를 사용하면 unlock시 모든 process가 깨어나는
(thundering heard) 문제가 발생한다.
그래서 hash table을 만들고 page들을 몇개씩(아마도 256개=PAGE_PER_WAITQUEUE?) 모아서
wait queue를 관리한다. hash collision이 발생하면 같은 hash index에 있는 process들이 모두
깨어 나긴 하지만 그래도 공간을 절약하는것이 더 낫다.
자세한 설명은 책과 include/linux/mmzone.h의 zone struct의 wait_table 멤버 설명에 나와있다.
그리고 책에서는 free_area_init_core() 에서 한다고 했는데
mm/page_alloc.c 를 보면 zone_wait_table_init() 함수에서 zone->wait_table을 계산한다.
책에 보면 wait_queue_siz를 계산하는 부분이 나오는데 log2를 하고 있어서 좀 이상하다.

2.3 Zone Initialization
paging_init()
UMA: free_area_init() -> free_area_init_node(0) -> free_area_init_core()
NUMA: free_area_init_node(0) -> free_area_init_core()

2.4 Initializing mem_map
UMA: global mem_map은 pglist_data(0)의(실제로는 contig_pgdat) 의 node_mem_map과 동일하며
alloc_node_mem_map() 함수에서 할당 받는다.
NUMA: global mem_map은 PAGE_OFFSET을 가리키고 그 virtual array 안에
pg_dat의 node_mem_map가 가리키는 page들의 주소가 저장되어 있다.
현재는 없어진 zone 안의 zone_mem_map이 가리키는 주소 또한 virtual array 안에 저장되어 있다.

ex)
UMA: 실제 map 주소 (0x12345678), global mem_map(0x12345678), node_mem_map(0x12345678)
NUMA: 0번 노드의 map 주소 (0x12345678), global mem_map(PAGE_OFFSET), PAGE_OFFSET[XX](0x12345678)
=> 확실치가 않다.

--------------------------------------------------------------------------------
[2014.04.26]
Chapter 2.5. Pages
struct page 에 대한 설명
모든 물리적 페이지 프레임은 struct page 로 관리됨
페이지의 status 를 추적하기 위해서

[list]
list_head 가 page 를 list로 관리함.
2.xv설명) clean_pages list, dirt_pages list, locked_pages 리스트가
존재함.
3.xv) 지금은 확실하지 않다.

[address_space* mapping]
memory mapped -> address space 가리킴.
1. 파일인경우: 파일 조작 address_space
2. anonymous & mapping is setted: swap address space

[unsigned long index]
1. 파일인 경우: 파일의 offset
2. swap_space: space address space offset
3. being freed: order of the block being freed -> stored in index -> 3.x
v에서는 이것이 void* freelist로 관리됨(3.x에서는 union을 이용한다.)

[next_hash]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[count]

[flags]

[lru]

[pprev_has]
-> 3.x에서는 존재하지 않음? (아직 확인하지 못함)

[buffers]
-> 3.x에서 buffer_head 사용에 관한 논의(bio를 씀?) (3.x v에서 확인 못함)
ref) http://blog.naver.com/kkn2988?Redirect=Log&logNo=141569528

[virtual]
void* virtual: 커널 메모리 영역(3~4GB)에서 ZONE_NORMAL까지는 direct mapping
되지만, kernel space에서 할당하는 ZONE_HIGHMEM영역은 kmap()으로 매핑된다.
이 kmap()으로 관리되는 영역을 virtual이 가리킴.

Pageflag
-- include/linux/page-flags.h 에서 확인 가능

Chapter 2.6. Mapping Pages to Zones
1. 2.4에서는 struct page마다 zone을 가리키는 포인터가 있었지만 2.6
이후로 삭제되고, 대신 SHIFT를 이용해서 접근함. zone을 위해서 pageflag의
일부 공간을 이용한다.
2. zone_table 의 자료 구조가 있는가? 3.x에서 아직 못찾았음.

Chapter 2.7. High Memory
32bit machine에서 4GB이상의 물리 메모리를 사용하기 위한 PAE등에 대한 설명

Chapter 2.8. What's New in 2.6
1. Zones 자료구조에 업데이트 된 부분들
: zone->lock, zone->lru_lock, zone->pageset과 같이 spinlock contention이 높은
자료구조들을 서로 다른 cacheline에 배치시키기 위해 zone 내부에 padding을 두는
trick을 사용함. (3.9 Level 1 CPU Cache Management 참조)

2. per_cpu_page 자료구조에 대한 의문점들을 아직 가지고 있다.

3. page_state 자료구조는 3.x에서는 사라진 것으로 보인다.

Chapter 3. Page Table Management

pgd_t datatype:
./arch/arm/include/asm/page.h 의 149부터 153번째 줄 참고(3단계인지
2단계인지 아직 명확하지 않음)

unsigned integer 를 structure로 define한 이유? :잘못된 사용을 막기 위해 +
PAE의 4bit를 위해: page granularity때문에 32bit모두 다 필요하지는
않다.((다시 확인해야함)

page granularity 만큼의 remaining bits는 다양한 용도로 사용(PAE 확장,
protection 등등)

--------------------------------------------------------------------------------
[2014.05.10]

Chapter 3. Page Table Management

3.1. Describing the Page Directory
-- 복습
-- Target architecture: 2-level pagetable(11-9-12bits)
-- Why different with x86? (10-10-12bits)
-- Find the references
3.2. Describing a Page Table Entry
-- protection bits usually stored in lower bits (also should find the reference)
-- Arm page protection define (./arch/arm/include/asm/pgtable.h)
-- 1. Hardware page table protection (./arch/arm/include/asm/pgtable-*level-hwdef.h ?)
-- 2. Linux page table protection
-- 차이점에 대해서 알아야 함.
3.3. Using Page Table Entries
-- pmd_bad(), pgd_bad() : we will figure out later
-- page table walk example: follow_page() -> 3.x에서 follow_page_mask()로 바뀜
3.4. Translating and Setting Page Table Entries
-- mk_pte, mk_pte_phys
-- 설명이 너무 간단해서 이해할 수 없다.
-- pfn_to_page, page_to_pfn macros: ./include/asm-generic/memory_model.h 참고
3.5. Allocating and Freeing Page Tables
-- quicklists: pages tables are cached(free가 되더라도 다시 allocation될 수 있으니, cache를 해놓는다)
-- 하지만 quicklists datastructure와 get_pgd_fast()등의 function들을 실제로 사용하고 있는 것은 확인하지 못했음
-- microblaze를 비롯한 일부 architecture dependent code에는 존재하는 것을 확인
3.6. Kernel Page Tables
--3.6.1. Bootstrapping
----8MB memory for Bootstrapping
----pg0 and pg1 point to that space
--3.6.2. Finalizing
---- x86 paging_init (page table 구성) 설명
---- paging_init() for x86: ./arch/x86/mm/init_32.c
---- paging_init() for arm: ./arch/arm/mm/mmu.c
---- paging_init() for x86
------ pagetable_init()
------ kmap_init()
------ zone_sizes_init()
3.7. Mapping Addresses to a struct page
--3.7.1. Mapping Physical to Virtual Kernel Addresses
--3.7.2. Mapping struct pages to Physical Addresses
----struct page 와 physical&virtual address translation에 대해서 다음주에 다시 보기
----swapper_pg_dir : for highmemory?
----VA 3~4GB에 해당하는 kernel memory는 offset +- 로 translation이 가능하고,
----그 이외에는 page table (pgd: swapper_pg_dir)을 이용할 것으로 생각중

--------------------------------------------------------------------------------
[2014.05.17]

3.8 Translation Lookaside Buffer (TLB)
PTE를 이용하여 매번 virtual address를 physical address로 바꾸기
힘드므로 associative memory에 저장하여 놓는다.

TLB의 구조(2way의 경우)
Index | Tag | PPN | valid | Tag | PPN | valid
index는 virtual address의 LSBs
Tag는 virtual address의 나머지 상위 비트
PPN Physcial Page Number
(way와 index의 크기는 2 dimension이며 trade off가 있다.?)

void flush_tlb_all(void) - 전체용
void flush_tlb_mm - context switch용
void flush_tlb_range - 부분용
void flush_tlb_page - page 단위 (가장 작은 단위)
void flush_tlb_pgtables - 특정 플랫폼에서는 pgtables 통채로 entry를 채운다.(?)
void update_mmu_cache - page fault 가 완료되었을 때 호출

Documentation/cachetlb.txt 참조
arm 쪽은 arch/arm/include/asm/tlbflush.h

3.9 Level 1 CPU Cache Management
Level 1과 2 cache가 보통 있는데 linux는 L1 cache만 신경쓴다.
L1_CACHE_BYTES = 2<<5 (1 line의 size)

cache의 종류
direct mapping = 1 way set associate mapping
full associate mapping = max way set associate mapping
set associate mapping = n way set associate mapping
용어
| tag | set(index) | offset |
tag : unique를 보장해주는 MSB
set : index, line을 나타내는 LSB
offset : 한 line 내에서의 offset
n-way : 같은 index를 가진 tag가 n개가 존재한다.

아래의 자료 참조
http://pds12.egloos.com/pds/200809/23/87/hardware_cache_schematic.pdf
민홍교수 ppt

cache를 잘 사용하기 위한 방법
1. 구조체에 자주 사용하는 field는 32bytes 안에 포함되게 앞부분으로 옮겨라
2. false sharing인 되지 않도록 cpus사이에서 사용하는 관계없는 데이터는 떨어 트려라
3. mm_struct 같은 경우는 false sharing을 피하기 위해 32byts align 되어 있다.
* false sharing
http://doriyun.tistory.com/18

* PIPT, VIPT, VIVT에 대한 정보(TLB를 비롯한 주소 변환 유닛들의 위치에 따라 달라짐)
VIPT의 경우 address 하위 12bits의 경우 physical이나 virtual이나
같기 때문에 이 하위 12bits를 이용하여 cache index(set)을 먼저 검출하는것이
가능하기 때문이 아닐지 추축해봄.
http://micol.tistory.com/m/post/257

3.10 What's New in 2.6
1. MMU-less Architecture 지원
mm/nommu.c

2. Reverse Mapping
Page에서는 그것을 이용하는 PTE를 알수가 없다. 이는 swap out할 때
shared page등을 검사할 경우 많은 비용을 수반하게 된다.
이를 위해서 page에서 이를 사용하고 있는 pte들을 가리키는
구조를 만들었다. union pte 이는 단일 pte를 가리킬수도 있고(대부분은 단일 pte이므로),
pte_chain이 될 수도 있다.
mm/rmap.c 가 관계가 있는지 다음 시간에 확인

--------------------------------------------------------------------------------
[2014.05.24]
* Reverse Mapping
- pte_chain에 관한 흔적은 예전 커널의 mm/rmap.c에서 볼수 있으나
현재는 찾을수 없었다.
rmap.c와 reverse mapping이 같은 것인지 잘 모르겠다.
include/linux/rmap.h , mm/rmap.c

* Object-Based Reverse Mapping
모든 page에 대해 reverse map을 유지하는 것은 비용이 많이 필요하므로
VMA(Virtual Memory Area)를 이용하여 관리한다.
VMA는 쉽게 생각하여 page의 시작과 끝을 나타내는 구조체이다.
아래 링크의 그림을 참조하면 쉽게 알수 있다.
kernel memory 구조에 대한 블로그.(How the kernel Manages Your Memory)
http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/

모든 pte를 찾아보려면 두가지 일이 필요한데,
하나는 page_referenced() (어느 페이지가 최근에 참조되었는지 알아보는 함수)
나머지 하나는 try_to_unmap이다.
page에 address_space *mapping 이란 필드가 있는데 이 부분이
reverse mapping이며 두가지 종류로 나뉜다.
하나는 backed file/device 이며, 하나는 anonymous 이다.
file/device의 경우 address_space라고 부르며,
anonymous는 swapper_space라고 부른다.

* kernel : page->mapping(address_space)->i_mmap -> 각 mm_struct들의 vma들의 rbtree
* process : mm_struct->mmap(vma의 list)

try_to_unmap_obj() 설명을 보면 여러 개의 프로세스가 많은 vma를 필요로 하는
하나의 파일을 열고 있을 때에는 object based reverse mapping보다
page based reverse mapping이 더 좋다고 설명하고 ㅣㅇ는데, 이는 앞 단락에 나온 pte_chain이
나오는 reverse mapping이 아닌가 추측되며, 현재는 없어진 것이 아닌가 추측된다.

object based reverse mapping에 관한 자료
https://www.kernel.org/doc/ols/2004/ols2004v2-pages-71-74.pdf

* PTEs in High Memory
PTE를 high memory에 위치 시킬 수 있다. 하지만 그만큼 병목이 될 수 있다.
pte_alloc_kernel()은 kernel PTE 용이고
pte_alloc_map() 은 userspace mapping용이다.
CPU당 하나의 PTE만 high memory를 이용할 수 있다고 하였는데, 그 이유는 모르겠다.

* Huge TLB Filesystem
linux는 전통적으로 kernel image만 4M page를 사용하였다.
HugePage를 이용하면 TLB slot에 큰 이득이 된다.
process가 hugepage를 두가지 방법으로 이용할 수 있다.

shmget() - shared region backed by huge page를 생성할 때 사용.
예를 들어 hugetlbfs에서 new file을
여러개 만든다고 할 때, 각자의 이름은 구분되어야 하고 이는 hugetlbfs_counter에
기록해야 한다. 이런것들에 대한 정보를 저장할 때 이용할 수 있다.
System V에서 넘어온 함수

mmap() - file open huge page filesystem
실제 파일을 open할 때 사용.
file이 open될 때 호출되는 함수. POSIX
만약 MAP_SHARED 옵션으로 호출한다면, shmget()과 비슷한 효과를 나타낸다.

자세한 사항은 Documentation/vm/hugetlbpage.txt 참조

* Cache Flush Management
flush_page_to_ram() 삭제
flush_dcache_range() 추가

--------------------------------------------------------------------------------
[2014.05.31]

Chapter 4. Process Address Space

Abstract
kernel 영역과 user 영역은 주소공간 관리가 다르다.
(예를 들어, kernel 에서 메모리 할당은 어떤 user task 인지 상관없이 globally visible 하기 때문이다.)
하지만 vmalloc은 Page table managemnt 가 필요하기 때문에 추가적인 오버헤드가 필요하다
(vmalloc 은 예외라고 볼 수 있다.)

4.1. Linear Address Space
커널 이미지를 위해 8mb 를 page offset 기준으로 예약한다.
(kernel image를 위해 페이지 테이블을 미리 초기화한다)

kernel address space 
vmalloc_reserved -> highmemory system 에서 최소 128mb를 예약함.
lowmemory system 에서는 더 커질수 있다. 1G - physical memory size 만큼
추가 설명은 7장 history 참조 

4.2. Managing the Address Space
vm_area_struct에 대한 설명 다시함.
System call lists : { fork, clone, mmap, mremap, munmap, shmat, shmdt, execve, exit }

4.3. Process Address Space Descriptor
kernel threads는 mm_struct가 필요하지 않다.
(vmalloc은 예외)
kernel threads는 메모리에 direct mapping 되어 있기 때문.

context switch 할 때 TLB flush overhead를 줄이기 위해서
active_mm을 함께 가지고 있음.(struct task_struct 참고)

mm_users (2로 초기화 됨)
mm_counters (1로 초기화 됨)

mm_users를 감소시킨 뒤에 mm_counters를 감소시키고,
0이 되면 mm_struct를 최종적으로 제거한다.

4.3.1. Allocating a Descriptor
4.3.2. Initializing a Descriptor
4.3.3. Destroying a Descriptor
--------------------------------------------------------------------------------
[2014.06.07]

4.4 Memory Regions
프로세스의 모든 주소공간은 거의  사용되지 않는다. 각각의  공간은 vm_area_struct에 의해 region으로 표현된다.
56페이지 그림 4.2 참조.
ex)
  region이 file과 연결된 메모리를 가지는 경우(backed by a file)의 경우
		 vm_area_struct -> vm_file -> inode -> address_space로 연결.

vm_area_struct 	: ./include/linux/mm_type.h
vm_flags 				: ./include/liinx/mm.h

4.4.1 Memory Region Operations
three operations : open, close, nopage.
	open, close : Resion이 생성되거나 제거될때 사용.
	nopage			: page fault가 발생할때 호출.
								vm_operation_struct -> gernric_file_vm_ops->nopage->filemap_nopage.

4.4.2 File/Device-Backed Memory Regions
address_space : inode->i_mapping과 page->mapping이 address_space를 가르키고 있다.
memory manager는 flush정보가 필요한데 a_ops를 통해서 정보를 알 수 있다.

vm_area_struct : 가상 주소 영역
address_space  : 물리 주소 영역(?)

address_space_operations : include/linux/fs.h
	실제 page를 다루는 함수들.

4.4.3 Creating a Memory Region
system call mmap() dl 프로세스 내에서 새로운 메모리 영역을 생성하도록 한다.
sys_mmap2()->do_mmap2()->do_mmap_pgoff() 로 호출시 파라메터 전달.
그림 4.3 참조. sys mmap2()
do_mmap2():   mmap() 호출시 linux에서 사용하지 않는 MAP_DENYWRITE 와 MAP_EECUTABLE 비트를 제거하고 파일에 맵핑될 경우 세마포어를 획득한다.
do_mmap_pageoff() : sanity check를 하고 파일이나 디바이스가 맵핑된경우 매핑된 사이즈가 페이지 얼라인 된지 확인하고 address space의 커널영역에 생성되지 않도록 한다.
1. 파라미터에 대한 sanity check를 한다.
2. 충분한 선형 주소 공간을 찾는다. get_unmmaped_area()->arch_get_unmmaped_area()
3. VM flage 계산하고 파일 접근 권한에 대해서 체크.
4. 매핑을 원하는 공간에 기존에 매핑된 역역이 있으면 새로운 매핑에 적합하게 기존 공간을 고친다.
5. slab 할당자로부터 vm_area_struct를 할당하고 해당 정보들을 채운다.
6. 새로은 VMA를 연결한다.
7. 파일시스템이나 디바이스에 맞는 mmap 함수를 호출한다.
8. update statistics and exit

4.4.4  Finding a Mapped Memory Region
find_vma()
mmap_cache field 체크. 마지막에 호출된 find_vma()의 결과를 가지고 있음.
만약에 요청한 영역이 아니면 mm_rb 필드에 저장된 red-black 트리에서 찾는다. 만약에 요구된 영역이 어떤 VMA에도 포함되지 않으면 이 함수는 요구된 영역과 가장 가까운 VMA를 리턴한다.
find_vma_prev() : find_vma와 동일하지만 이전 VMA의 위치도 리턴한다.
find_vma_intersection() : 요구된 주용소공관과  겹치는 VMA를 찾기 위해 사용.
vma_merge() : VMA 확장에 사용. VMA가 앞쪽으로 확장할수 없으면 뒤로 확장한다.
get_unmapped_area() 충분한 공간을 찾기위해 사용.

4.4.5 Finding a Free Memory Region
 get_unmmapped_area -> arch_get_unmapped_area(or generic version in mm/mmap.c) -> find_vma

4.4.6 Inserting a Memory Region.
메모리 영역 추가는 insert_vm_struct()을 사용.
이것은 VMAs 사이에 적당한 VMA를 찾기위해 find_vma_prepare() 를 호출하고 
새로운 VMA의 연결을 위해 vma_link를 호출한다.
insert_vm_struct()는 map_count field가 증가하지 않기때문에 잘 사용되지 않고 
map_count를 증가시켜주는 __insert_vm_struct()를 사용한다.

insert_vm_stuct()함수를 사용하지 않고 find_vma_prepare()를 호출한 후  vma_link()를 호출한다. 시간을 줄이기 위해.

4.4.7 Merging Contiguous Regions
merge_segments()대신에 vma_merge()를 사용.
vma_merge()는 sys_mmap(), do_brk()에서 사용된다.
함수를 사용하지 않아도 합쳐지는 경우가 있는데
첫번째는 sys_mprotect()가 호출된경우, mprotect()로 permission이 변경된경우 인접한 영역은 합쳐진다.
두번째는 move_vma()가 호출된 경우, 옆에 위치한 동일할 영역이 합쳐짐
 brk() : http://www.nxmnpg.com/ko/2/brk

4.4.8 Remapping and Moving a Memory Region.
mremap()->sys_mremap()-.do_mremap()->get_unmapped_area()
메모리 영역을 이동하기위해서 충분한 공간을 찾는다.
충분한 공간이 있으면 move_vma()를 호출.
move_vma()는 인접한 VMA들 에 합쳐질 수 있는지 체크하고 
그렇지 않으면 새로운 VMA가 하나의 PTE에 할당한다. 
그리고 move_page_tables()를 호출한다.

이때 사용되는 zap_page_range()의 경우 실제로 페이지를 복사하거나 옮기는것이 아닌
swap out만을 시키고 나중에 page fault handling 코드를 이용하여 다시 swap 한다.

 4.4.9 Locking a Memory Region
mlock()->sys_mlock()을 이용해서 pages(region)를 lock 할수 있다.

mlockall()->sys_mlockall()

==> do_mlock

메모리 lock의 3가지 제한 사항.
1.VMA가 page aligned되어 있다.
2.프로세스가 ystem admin에 의 해 설정된 RLIMIT_MLOCK의 한계가 있다.
3.각 프로세스는 한번에 물리메로리의 절반만 락을 걸수 있다. root process만 pages를 lock을 할 수 있다.

4.4.10 Unlocking the Region
munlock(), munlockall()
sys_munlock, sys_munlockall()
==> 이 함수들은 regions을 수정하기 위해서 do_mmap()에 의존한다.

----------------------------------------------------------------------
[2014.06.14]
4.4.11 Fixing Up Regions After Locking
locking/ unlocking을 할 때, VMA들은 4가지 방버으로 영향을 받는데,
이는 mlock_fixup() 에 의해 수정이 되어야 한다.
mlock_fixup_all(), mlock_fixup_start(), mlock_fixup_end(), mlock_fixup_middle()
흥미로운 점은 locking의 결과로 생성된 VMA들은 lock이 풀리더라도 merge되지 않는다.
- 현재 커널에서는 많이 수정된 듯하다.

4.4.12 Deleting a Memory Region
do_munmap()
  1. red-black tree와 linked list를 수정
    - 만약 부분적인 unmap이라고 할지라도, 일단 삭제하고 unmap_fixed()에서 다시 생성
  2. 관련된 page를 release하고 PTE를 unmapped시킴
    - 이때 PGD를unmap할지라도 PTE를 free하지는 않는다. (비용문제)
  3. 만약 region에 구멍이 생기면 수정함

4.4.13 Deleting All Memory Regions
exit_mmap()을 통해 모든 VMA를 unmap 한다.
그리고 TLB를 flush하고, PTE를 지운다.

4.5 Exception Handling
page fault에 대한 bad reference excetpion만 다루기로 한다.
두 가지 경우가 발생할 수 있는데,
  1. PAGE_OFFSET 이상을 접근할 경우, (4.6?) 잘 이해가 안됨
  2. copy_from_user(), copy_to_user() 의 userspace를 접근하는 함수를 실행할 때 (4.7)
__ex_table이 linker에 의해 생성되며, execution point와 fixup routine으로 구성된다.
exception이 발생시 page fault handler가 manage를 못하면,
search_exception_table()을 호출하고 여기서 대응되는 fixup code의 위치를 찾아서 호출한다.

4.6 Page Faulting
page들이 모두 메모리에 상주할 필요는 없다. 
linux는 Demand Fetch policy르 사용하는데 이는 하드웨어가 page fault exception을
일으키면 backing storage로 부터 fetch되는 것이다.
backing storage의 특성상 prefetch를 이용하면 더 적은 page fault를
일으킬 수 있는데 linux에서는 이 부분에서 좀 원시적이다.
page in될 때 2^ page_cluster만큼 swapin_readahead()만큼 읽어 오지만 불행하게도
곧 사용될 근처의 page들만 읽어오는데 이는 prepaging policy를 형편없게 만든다.

page fault는 major와 minor로 나뉘는데, major page fault는 disk로부터
데이터를 읽어 올때 발생한다. 이것은 아주 비싼 동작이다.
이는 task_struct->maj_flt, task_struct->min_flt에 기록되어 있다.

page fault의 종류
1. Region valid, but page not allocated (Minor)
2. Region not valid but is beside an expandable region like the stack (Minor)
3. Page swapped out, but present in swap cache (Minor)
4. Page swapped out to backing storage (Major)
  - swap-out되어 있으나 pte는 남아 있어, pte를 찾고 disk로 부터 읽어온다.
5. Page write when marked read-only (Minor)
  - COW를 wirte할 때
6. Region is invalid or process has no permissions to access (Error)
7. Fault occurred in the kernel portion address space (Minor)
  - vmalloc area에서 발생할 때, init_mm에의해 현재 process의
    page table들이 master page table에 update 될때. 유일한 kernel page fault
8. Fault occurred in the userpsace region while in kernel mode (Error)

page fault를 처리하는 함수의 이름은 do_page_fault()이고 이는 어러가지 일을 한다. (책 참조)
그중 handle_mm_fault()는 page from backing storage와 COW를 처리한다.

4.6.1 Handling a Page Fault
1. valid한 region인지 검사
2. handle_mm_fault()에서 pmd와 pte가 없을 경우 alloc함
3. pte의 상태에 따라 세가지 경우로 나뉨 (pte bits p.36)
 - 1) pte_present()와 pte_none()을 봄
     - pte_none() - true: 아예 allocation된적이 없다.
                          do_no_page() 호출 -> Demand Allocation(4.6.2 절)
     - pte_none() - false: pte_present()를 체크
     - pte_present() - true: page_fault()가 불릴 이유가 없다.
     - pte_present() - false: alloc된적 있으나 swapped -out되서 내려갔다. 
                              do_swap_page() 호출-> Demand Paging(4.6.3 절)
                              do_no_page()를 호출하는 희귀한 경우가 virtual file일 경우 있음

   2) pte의 write protected인 경우
     do_wp_page()를 호출 - 왜냐면 page가 COW page이기 때문.
     COW page는 여러 포르세스들(부모와 자식)에 의해 공유되는데
     COW page인지 인식 방법은 PTE에서는 모르지만(?) VMA에 writable로 마크(p.63)되어 있기 때문이다.

   3) pte가 이미 read 되어 있고 present인 경우
     3 level page table을 가지지 않은 특정 아키텍쳐에서 발생하는데, young(accessed)으로 마크한다.
     왜 그런지는 다음 시간에...
     
----------------------------------------------------------------------
[2014.06.21]
4.6.2 Demand Allocation
do_no_page() 함수에 의해 수행
vma의 종류는 file/device backed pages와 anonymous pages가 있다.
file/device는 memory-mapped device나 파일로 vm_operations(p.64)이 제공되며
그중 nopage() 함수를 호출한다.

-Handling Anonymous Pages
vm_area_struct->vm_ops 필드가 없거나 nopage() 함수가 없으면,
anonymous page로 분류되며 do_anonymous_page()가 호출된다.
첫 읽기일 경우 write protection이 걸려있는 empty_zero_page로 연결되어 있다.
만약 쓰기 요청이 들어오면 다른 page fault가 발생할 것이다.
ex) kernel source
init/main.c - start_kernel()
    ->arch/arm/kernel/setup.c - setup_arch() 
        ->arch/arm/mm/mmu.c - paging_init()
의 소스를 보면 page table들을 초기화 한 후 empty_zero_page를 만든다.

첫 쓰기일 경우, alloc_page()가 호출이 되고, clear_user_highpage()에 의해
0으로 채워진다. 그리고 mm_struct에 RSS(사용되는 페이지수를 나타냄. p.59)를
하나 증가 시킨다. 특정 아키텍쳐에서는 cache coherency를 높이기 위해 user space
process에 추가 될 때는 flush_page_to_ram()이 호출된다고하는데 잘 모르겠음.
그리고 나중에 재사용(?)을 위해 LRU list에 추가된다.
마지막으로 page table entry가 갱신된다.


-Handling File/Device-Backed Pages
vm_operation 의 nopage()가 제공된다.
file backed 의 경우 filemap_nopage()가 사용되고
virtual file(shmfs)의 경우 shmem_nopage()(ch.12)가 사용되며
각가의 device마다 각각의 nopage()를 제공해야 한다.
valid한 page만 return한다면 내부는 어떻게 만들어졌든 상관이 없다.
page 가 return된 후 체크를 해야 하는데
COW 에 의한 것인지 pte_none()에 의한 것인지에 대해서이다. (자세한 것은 pass)

4.6.3 Demand Paging
backing storage로 swapped out 되어 있을 때 발생하며,
virtual file의 경우는 12장에서 다시 살펴 본다.
shared될 수도 있으니 swapped out이 바로 되지 않고, swap cache에 위치 시킨다.
(RMAP이 생겨서 바뀔 것이르 추측됨)
swap cache에 이미 있을 경우 minor page fault로 reference count만 증가 시키면 되고,
disk에 있을 경우 swapin_readahread()가 호출된다.
low memory machine에서는 보통 2^2, 2^3 page정도이다. (16K ~ 32K)

4.6.4 COW pages
do_wp_page() . 설명은 생략
fork시에 두 프로세스의 pte는 read-only로 되는데
write 요청이 발생하면 PTE write protected되어 있다 할지라도
VMA가 writable이면 이것을 보고 인식하여 do_wp_page()를 수행함

4.7 Copying to/from Userspace
생략

[2014.06.28]
4.8 What's New in 2.6
--Linear Address Space
  vsyscall support 추가. (int 0x80 을 통한 시스템콜이 아니라 userspace page <-> kernel space page 의 매핑을 이용함)
--mm_struct
  free_area_cache (first hole을 알려주는 필드) 를 추가하여 searching time을 절약 
--vm_area_struct
  vm_next_share와 vm_pprev_share 을 shared 필드 하나로 합침
--struct address_space
  gfp_mask field 를 비트 단위로 나누어 두 개의 flags 를 저장한다. (다시 말해, 추가적으로 asynchronous I/O의 상태를 저장하는 flag를 가진다)
  [struct address_space 의 추가적인 필드]
  1. page_tree: linked list -> radix tree 로 변경
  2. page_lock: page_tree 를 보호하는 spin lock
  3. io_pages: do_writepages() 호출하기 전에 메모리의 io_pages list 에 임시 저장
  4. dirtied_when: jiffies 저장
  5. backing_dev_info
  6. private_list: buffer_head를 가리킨다.
  7. private_lock: private_list를 share하는 address_space 간의 private_list를 보호한다.
  8. assoc_mapping
  9. truncate_count
  [struct address_space_operations 의 operations]
  1. writepage:
  2. writepages:
  3. set_page_dirty:
  4. readpages:
  5. bmap:
  6. invalidatepage:
  7. direct_I/O:
--Memory Regions
security module 과 vm area 계정 관리 추가
--4GiB/4GiB User/Kernel Split
1gb 의 kernel 영역은 메모리 사이즈가 커지면, 부족할 수 있다 (mem_map 때문) 이를 해결하기 위한 patch가 있지만 아직 mainstream은 아니다.
--Nonlinear VMA Population
----생략

----------------------------------------------------------------------
Chapter 5. Boot Memory Allocator
Boot Memory Allocator (First Fit style allocator)
--5.1. Representing the Boot Map
  struct boomem_data (Boot memory allocator) 에 대한 설명
--5.2. Initializing the Boot Memory Allocator
--5.3. Initializing bootmem_data
  UMA, NUMA 에서 bootmem_data 초기화
  처음에 bitmap의 bit들을 모두 1로(사용중) 초기화하고, 0(free)으로 바꾸는건 architecture dependent 코드에서 각각 이루어짐
  free_bootmem()을 통해서 0으로 set함
--5.4. Allocating Memory
  memory allocation이 어떻게 이루어지는지 설명
  goal: preferred starting address (first fit allocation), zone_dma (low function) 은 goal 이 0, zone_normal 은 goal 이 MAX_DMA_ADDRESS가 된다
--5.5. Freeing Memory
  페이지의 4KB 모두 free 가 되면 bitmap의 bit를 0으로 바꿈
--5.6. Retiring the Boot Memory Allocator
  Boot memory 를 해제하고 다음 단계의 memory allocator로 전환하는 과정 (각 architecture는 mem_init()을 통해 위의 과정을 제공해야 함)
  free_all_bootmem(UMA), free_all_bootmem_node(NUMA) 를 이용
  free_all_bootmem_core 에서 비트맵의 비트를 모두 1로(사용하지 않은 페이지도 모두 1(사용중)로 세팅) 세팅하고 그 후에 __free_pages()를 통해서 메모리 해제와 buddy allocator 구성을 함께 한다
  이것을 highmemory 영역에 대해서 같은 과정(1로 세팅 후에 다시 __free_pages())을 수행한다
  __init section 은 system start_up 동안에만 사용되는 코드 영역들로, boot memory 를 해제할 때 boot allocator 데이터 영역 뿐 만 아니라, 코드 영역도(bootstraping code section) 메모리에서 free한다
--5.7. What's New in 2.6
  last_success field 추가: search time 감소를 위해서 free가 되면 free된 위치를 last_success가 가리킨다 (offset은 이전과 같음)
  BITS_PER_LONG: BITS_PER_LONG의 블록이 모두 1인지 검사하고, 아니라면 그 때 각각의 bit를 검사
  NUMA & contiguous architecture: contiguous architectures는 자신의 아키텍쳐만의 init_bootmem() 을 정의할 수 있고, 어떤 아키텍쳐도 각자의 reserve_bootmem()을 정의할 수 있다


----------------------------------------------------------------------
[2014.07.12]

mem_map 초기화 
./init/main.c - setup_arch()
./arch/arm/mm/mmu.c - paging_init()
./arch/arm/mm/init.c - bootmem_init()
                       arm_bootmem_free()
./mm/page_alloc.c - free_area_init_node()
                    alloc_node_mem_map()

kernel to physical (real) hardware memory mapping
커널 영역 (3~4gb) 에서 실제 물리 메모리로 매핑하기 위해서 offset을 빼준다.
우리 architecture 에서는 실제 물리 메모리가 0x40000000 부터 시작하고,
커널 메모리는 0xC0000000 부터 시작한다.
그 커널 메모리에서 0x80000000 을 빼서 실제 물리 메모리와 매핑이 된다.
유저 영역 (0~3gb) 는 pgd 를 이용해서 매핑이 됨.

----------------------------------------------------------------------
[2014.07.19]

mm_init() -> mem_init() 분석 중
mm/page_alloc.c
__free_pages_bootmem -> __free_pages() -> __free_pages_ok() -> free_one_page() 분석 중 마침
다음 시간 virtual memory management 책 6 장 읽고 다시 코드 분석 할 예정

----------------------------------------------------------------------
[2014.07.26]

Virtual Memory Manager. Chapter 6. Physical Memory Allocator

6.1. Managing Free Blocks
  struct free_area:
  map: bitmap [2.4 커널에서만 있음] order 에 따라 비트(맵)의 개수가 달라진다. (order = 9 -> 1개, order = 0 -> 256개, 합은 511개)
  nr_free: 3.x 에서 free page blocks 의 개수를 알려주는 unsigned long data type 있음

6.2. Allocating Pages
  __alloc_page : 3.x 커널에서는 다양한 여러 함수이 있음 (e.g., __alloc_pages_high_priority(..))
  __alloc_pages_nodemask(..): the 'heart' of the zoned buddy allocator
  _alloc_pages 없어짐. 호출과정이 변경됨.

6.3. Free Pages
  2.4 kernel mm/page_alloc.c -> -mask = 1 + ~mask ? (최적화인가?)

6.4. Get Free Page (GFP) Flags
  GFP 플래그들: ./include/linux/mm.h -> ./include/linux/gfp.h (3.x) 로 변경

6.5. Process Flags
6.6. Avoiding Fragmentation
6.7. What's New in 2.6

----------------------------------------------------------------------
[2014.08.02]
Chapter 7 Noncontiguous Memory Allocation
cache와 memory-access-latency 때문에 많은 양의 메모리를 다룰 때는연속적인
실제 메모리 페이지를 사용하려고 한다. 하지만 buddy allocator의
external fragment 때문에 항상 가능하지는 않다. linux는 vmalloc()을 통해서
불연속(nocontigouous)한 물리 메모리를 연속적인 가상메모리로 제공한다.
VMALLOC_START와 VMALLOC_END사이에 그 공간이 예약되어 있는데, 이 부분은
x86의 경우 최소 128MB(VMALLOC_RESERVE)이다. p.54에 있는 그림 참조
만약 1G 이상의 물리 메모리를 가졌다면
    VMALLOC_START는 3G + 896M 가 VMALLOC_START이다. (reservered 128M)
만약 512M의 물리 메모리라면
    VMALLOC_START는 3G + 512 + VMALLOC_OFFSET(8M) 이다. (reserved 512M 근처) 
(VMALLOC_OFFSET이 항상 포함되는지는 잘 모르겠음)

7.1 Describing Virtual Memory Areas
struct vm_struct{} // <linux/vmalloc.h>
위의 구조체를 이용하여 list로 운영되며 adress로 정렬되어 있다.

7.2 Allocating a Noncotiguous Area
vmalloc(), vmalloc_dma(), vmalloc_32()를 이용하여 할당
vmalloc_area_pages()를 위한 master page table은 init_mm->pgd 에 있으며
한 프로세스가 page fault exception을 일으키면 init_mm->pgd를 이용하여
PGD, PMD, PTE를 할당하고 최종적으로 alloc_page()를 호출한다. 그리고 이것을
이용하여 현재 프로세스의 page table을 update한다. (그림 7.3 참조)

7.3 Feeing a Noncontiguous Area
vmalloc_area_pages()의 반대되는 함수로 vmfree_area_pages()가 존재

7.4 What's New in 2.6
map_vm_area() array가 추가. 정확히는 모르겠다.
get_vm_area()와 vmap()도 변화가 있다고 하나 생략

code review
init/main.c - mm_init()
  init/main.c - mem_init()
    arch/arm/mm/init.c - free_unused_memmap() // bank와 bank사이의 사용하지 않는 부분 free. 이유 모름
    mm/bootmem.c - free_all_bootmem()
      mm/bootmem.c - free_all_bootmem_core()
        mm/page_alloc.c - __free_pages_bootmem() // order에 따라 buddy를 이용해 free
          mm/page_alloc.c - __free_pages()
            mm/page_alloc.c - free_hot_cold_page() // order 1일 때 호출되며 lru에 넣거나
                // free_pcppage_bulk를 호출. 다음시간 할 차례
            // free_pages_prepare도 안봄

----------------------------------------------------------------------
[2014.08.16]
              mm/page_alloc.c - free_pcppage_bulk()
                mm/page_alloc.c - __free_one_page()
  buddy를 검사하고 buddy가 free이면 다음 order로 이동.
  합쳐지는 루틴이 끝난후 다음 order까지 검사해 보고
  더 합쳐질 가능성이 있으면 lru를 freepage의 뒤로 넣고
  아니면 앞으로 넣는다.
  CompoundPage는 HugeTLB(HugePage)를 이용할 때 여러 개의
  페이지를 합쳤다는 뜻으로 최근에는 PG_tail과 PG_head로 세분화 되었다.
  page->lru는 무엇인지 잘 모르겠다.

                  mm/page_alloc.c - page_is_buddy()
  buddy가 page가 guard page이면서 order가 같거나
  buddy가 free(PageBuddy()호출)이면서 order가 같을 경우 true이다.

  다음 시간 lru의 정체를 밝혀보자.

----------------------------------------------------------------------
[2014.08.23]

1. mm_init()->mem_init(): 버디 할당자 초기화
코드 분석 완료
2. mm_init()->kmem_cache_init(): 슬랩(슬랩/슬롭/슬럽) 할당자 초기화
코드 분석 시작
3. Understanding Linux Virtual Memory Management 책
챕터. 8. 슬랩할당자 시작: Introduction 까지 읽음

다음 시간:
Understanding Linux Virtual Memory Management 책 읽고(8.1. Cache 부터),
kmem_cache_init() 슬럽 부분 분석하도록 한다.

그리고:
page->lru 는 아직 확인 못함.

----------------------------------------------------------------------
[2014.08.30]
8.1 Caches
/proc/slabinfo 를 하면 cache descriptor 정보가 나온다.

8.1.1 Cache Descriptor
각 object type 별로 cache에 저장될 때 사용할 정보를 만들어 놓는다.
kmem_cache_s 구조체는 kmem_cache로 바뀌었으며
현재 커널에서는 slab 은 include/linux/slab_def.h에
slub은 inlclude/linux/slub_def.h 에
slob은 inlclude/linux/slab.h 저장되어 있다.

8.1.2 Cache Static Flags
CFGS_OFF_SLAB

SLAB_HWCACHE_ALIGN : L1 CPU cache 크기에 align
SLAB_NO_REAP: 메모리가 모자를 때 reap하는데 이때 reap 하지 않도록...

8.1.3 Cache Dynamic Flags
kmem_cache_grow()되면 set되는데, set이 되면 kmem_cache_reap()시에 한번
넘어가게 되서 reap 되지 않는다. 하지만 넘어가면서 clear된다.

8.1.4 Cache Allocation Flags

8.1.5 Cache Coloring
L1_CACHE_BYTES에 맞춰(pentium 2는 32 bytes, 우리 ARM은 64bytes) object가
cache될 때 몇개의 line을 사용하는지를 계산 해 놓는다.
colour 는 추가 offset 개수
colour_off 는 각 offset 크기
100 bytes object는 colour는 3이고 colour_off는 32. (PII 에서.)

8.1.6 Cache Creation

8.1.7 Cache Reaping
kswapd에 의해 메모리가 부족하게 되면 하나의 cache를 선택해
메모리를 줄인다. SLAB_NO_REAP이면 넘어가고, DFLGS_GROWN이면 한번 넘어간다.
선택된 cache는 slabs_free의 절반을 free 시킨다.

8.1.8 Cache Shrinking
per-CPU caches에 있는 모든 object를 삭제한다.
gwrowing하고 있지 않다면 slabs_free에 있는 slab도 삭제한다.

8.1.9 Cache Destroying

8.2 Slabs

8.2.1 Stroing the Slab Descriptor

8.2.2 Slab Creation

8.2.3 Tracking Free Objects

8.2.4 Initializing the kmem_bufctl_t Array

kmem_bufctl_t 는 고정된 사이즈의 array 로, 각 element 는 각 object 의
offset (또는 포인터) 을 가리키게 됨.
각 element 에는 다음 free object 의 index number 를 저장하고 있어서
free object 를 관리한다.
free 변수가 가장 상위의 free element 를 저장하고 있어 stack 처럼 동작
하게 된다.
자세한 내용은 책을 참고.

----------------------------------------------------------------------
[2014.09.13]

8.2.5 Finding the Next Free Object
object 에서 다음 free object 를 찾는 방법 설명.
kmem_bufctl_t[slab_t->free]; // free 는 다음 free object 의
index value 를 가지고 있다.

8.2.6 Updating kmem_bufctl_t
kmem_bufctl_t 의 값을 갱신하는 내용 관련.
kmem_bufctl_t 의 값은 오직 어떤 object 가 free 할 때 변경된다.
element 의 값이 다음의 free object index value 를 가진다.
free 변수는 이 값을 읽어 다음에 사용할 free object 의 index value 를
가지게 된다.

8.2.7 Calculating the Number of Objects on a Slab
slab 을 만들 때, kmem_cache_estimate 에서 얼마나 많은 object 개수가
생기는지, 얼마나 많은 bytes 가 낭비되는지 (cache coloring, fragmentation)
등을 계산한다.

8.2.8 Slab Destroying
slab 을 shrunk 하거나 destroy 할 때와 관련된 내용.
각 object 의 destructor 가 불린다.

8.3 Objects
slab 에서 object 들의 할당 및 해제 과정

8.3.1 Initializing Objects in a Slab
kmem_cache_init_objs(): initializing the objects

8.3.2 Object Allocation
kmem_cache_alloc(): 한 object 할당. slab_partial 먼저 채우고 slab_free 에서 채움.
slab_free 가 없으면, slab 을 더 확장한다.
object 할당은 UP 와 SMP 에서 다르게 동작하는데,
SMP 에서 percpu cache 를 사용한다는 것이 다르다.
이 부분은 8.5 장을 더 읽어보고 자세히 이해하도록 한다.

8.3.3 Object Freeing
kmem_cache_free(): destructor 를 호출하면서 object 를 해제하고 초기화한다.
할당과 마찬가지로 UP 와 SMP 에서 다르게 동작하는데,
역시 SMP 에서 percpu cache 를 사용한다.

8.4 Sizes Cache
자주 사용되는 data structures 뿐 만 아니라, 범용 목적 (그리고 DMA) 을 위해서
2의 멱승의 sizes 를 slab 으로 예약해 놓음 (일반과 DMA 각각)
# cat /proc/slabinfo

8.4.1 kmalloc()
8.4.2 kfree()
kmalloc 및 kfree 는 slab 을 이용하는 메모리 할당/해제 interface 정도로 보면 됨.

< on-cache, off-cache >
on-cache: slab_t, bufctl 이 object 들과 한 페이지에 함께 있는 경우
off-cache: object 들이 slab_t (bufctl) 과 다른 페이지에 떨어져 있는 경우
: object 의 사이즈가 작아서 아주 많은 buf index 가 필요한 경우 off-cache 가 됨.

8.5 Per-CPU Object Cache
Per CPU 마다 object pointer 들의 집합을 가지고 있다.
Per CPU 에서 관리되는 Object Cache 는 CPU 들 사이에서 disjoint 되어 있기 때문에,
spin lock 등을 하지 않아도 된다.
Per CPU object cache 들은 memory pool 처럼 동작한다. (해제 시에 곧바로 destroy 
하지 않고, 나중 할당 시에 이용할 수 있도록 한다.) -> 이 부분은 좀 더 확인이 필요하다.

8.5.1 Describing the Per-CPU Object Cache

8.5.2 Adding/Removing Objects From the Per-CPU Cache

8.5.3 Enabling Per-CPU Caches

8.5.4 Updating Per-CPU Information

8.5.5 Draining a Per-CPU Cache

8.6 Slab Allocator Initialization

8.7 Interfacing With the Buddy Allocator

8.8 What's New in 2.6

----------------------------------------------------------------------
[2014.09.20]
kmem_cache_s 는kmem_cache로 바뀌어 각 slab_def(SLAB), slab.h(SLOB), slub_def 등에 있으며
kmem_list3는 kmem_cache_node로 변경되었다.
cpucache_s는 array_cache로 변경되었다. (mm/slab.c)

array_cache에 대한 설명은 UnderstadingKerenel P.335
Local Caches of Free Slab Objects를 참조
간략히 설명하면 slab으로 부터 하나씩 freed object를 얻어 오기 힘드므로
cache 개념을 이용하여 batchcount 만큼 한번에 가져오고 해제하는 방식으로 동작한다.
avail은 실제 slab object가 들어 있는 array의 index를 나타낸다.
또 추가적인 정보는 다음 링크를 참조한다.
동적 메모리 할당자 : slab, slub, slob - http://studyfoss.egloos.com/viewer/5332580

void __init kmem_cache_init(void)
  책의 cache_cache는 kmem_cache_boot로 변경
  - int __kmem_cache_create (struct kmem_cache *cachep, unsigned long flags) 도중 마침

----------------------------------------------------------------------
[2014.09.27]
cache_cache인 "kmem_cache"를 설정하였고, 이를 slab_caches라는 전역 head에 저장한다.
__kmem_cache_create()는 slab의 size를 결정하고, slab당 들어가는 object 개수,
  gfporder등, kmem_cache 구조체의 값들을 설정한다. 그리고 array_cache 및 node를
  초기화 한다.

그 후 "kmalloc-ac"와 "kmalloc-node"를 실제로 slab으로 만든다.

TODO : kmem_cache 자체의 object allocation은 안해도 되는것인가?

----------------------------------------------------------------------
[2014.10.18]
- RW lock 
http://xucxo.blogspot.kr/2011/03/linux-programming-thread-rw-lock.html
장점: 1 write thread, many reader thread에 유리 
단점: writer가 굶을 수 있다.

- seq lock
장점: reader가 lock이 필요없다. writer가 굶지 않는다.
단점: reader가 틀린 값을 가지고 있을 수 있도고 가정

- RCU
https://app.box.com/shared/x5r7ugx6o6
장점: 변경되는 부분을 copy하여 만들고,
원래 값을 가지고 있던 reader는 그것을 사용. 특히 pointer 구조에 사용

- spin lock

- CAS?

참고 자료
NDC2012 병렬 프로그래밍
http://www.slideshare.net/tatis3/ndc12-12700288

NDC2014 멀티 쓰레드 프로그래밍이 왜이리 힘드나요?
http://www.slideshare.net/zzapuno/kgc2013-3

NDC2014 헤테로지니어스 컴퓨팅 CPU -> GPU
http://www.slideshare.net/zupet/ndc14-gpu


User space: pthread_mutex, pthread_rwlock

================================================================================
2014.10.25
Red Black Tree visualziation
https://www.cs.usfca.edu/~galles/visualization/RedBlack.html

* 리눅스 커널 내부구조 3장
fork(), vfork() -> process 생성, 내부적으로는 do_fork()
pthread_create() -> thread 생성, 내부적으로는 do_fork()
clone() -> 옵션에 따라 둘 다 생성, 내부적으로는 do_fork()

* context switching은 언제 하나?
time-slice를 다 사용하면 누가 그것의 context를 저장하고, 다음 context를
load하는가? timer interrupt?

* signal catch timing
task_struct에서 signal을 설정만 해놓고,
kernel level에서 user level로 돌아오는 타이밍에 실행되는 것이라면
무한루프 프로그램을 돌렸을때 제대로 안 멈추는 것은
system call이 없기에 바로 signal을 catch하지 못하고 다음 time slice를
사용할때 catch 하기 때문 아닐까?
http://www.iamroot.org/xe/QnA/41643

* Scheduler 정책
SCHED_FIFO : 0 ~ 99 -> RT
SCHED_RR   :  0 ~ 99 -> RT
SCHED_NORMAL(OTHER), BATCH, IDLE: 100 ~ 139 -> O(1), CFS
http://www.iamroot.org/xe/QnA/35618

* O(1)
running과 ready 상태에 있는 thread를 표현하는 runqueue 라는 구조체안에
active와 expired가 있는데, 실행후 active에서 expired로 옮긴 후 모두 다
옮기고 나면 active와 expired를 swap 한다.
Q: O(1) 스케줄러가 비선점형 커널의 주요 원인인가?

================================================================================
20141101
code review

================================================================================
20141108
shched_init() 시작
	리눅스 스케쥴러의 변천사 O(1), CFS
		http://enginius.tistory.com/97

	init_defrootdomain():
		1. cpupri를 위해 메모리를 할당 받고 각 cpu별 cpu_to_pri를 CPUPRI_INVALID=-1로 설정.
			cpupri_init :
				 참고)http://code.google.com/p/linuxkernel-iamroot/source/browse/trunk/kernel/sched_cpupri.c?r=60
	init_rt_bandwith()
		1. rt_bandwith의 rt_period, rt_runtime을 초기화
		2. hrtimer( high resolution timer) 초기화    참고)http://studyfoss.egloos.com/viewer/5268468
			 각 cpu별 hrtimer 및  timequeue 초기화	
				.CLOCK_REALTIME (0) : 현재 시간을 기준으로 하여 시간을 계산한다. 시스템 시간 변경 시 영향을 받는다.
				.CLOCK_MONOTONIC (1) : 커널이 동작한 시간을 기준으로 하여 시간을 계산한다. 외부의 영향을 받지 않는다.
			-clock source의 종류
				.RTC(real time clock)
				.PIT(programable interval timer)
				.hpet(high precision event timer)
				.TSC(time stamp counter) : cpu 안에 들어있는 HW counter
			timerqueue_init(&timer->node) : rb_node에 대해서 RB_CLEAR_NODE
		3. hrtimer_forward() : 다음 interval을 위해서 만료 시간을 이 함수가  리턴되기 전에 설정해 둔다. 
				그래야 다음 event시에 만료 시간을 알 수 있다. 
			period 는 interval을 의미.

                    timer                                current time
											& -> forword or advancing           

           -----------7----+------------+-------------+------**------
                         
									ovrrun   1            2             3      ; 현재 overrun 값은 3

참고)professional Linux kernel Architecture(p.925)에서
Let us illustrate the behavior by an example. If the old expiration time is 5, now is 12,
and interval is 2, then the new expiration time will be 13. The return value is 4 because
13 = 5 + 4 × 2.    overrun: 4개 (5, 7, 9, 11) 


The high-resolution timer API
참고) http://lwn.net/Articles/167897/
		리눅스 커널 심층분석, 리눅스 커널의 이해

메모리에서는 주소가 중요하다면, CPU에서는 시간이 중요하다.

================================================================================
2014.11.15

[Group & Scheduling in Linux]
(http://lwn.net/Articles/80911/)
(http://sunjinyang.wordpress.com/2010/10/06/linux-kernel-scheduling-domains-and-classes/)

Scheduling domain(스케줄링 영역): 스케줄링 그룹 자료 구조와 함께 구성되며
계층적인 방식으로 전체 시스템의 영역을 구성한다.
속성(properties)과 정책(policies)를 공유하는 cpu 집합으로, 해당 cpu 간에 부하가 균등하게 조절됨.
스케줄링 영역은 스케줄링 그룹을 한 개 이상 포함하기 때문에 스케줄러가 한 영역 내에서의
균형을 유지하려 할 때 그룹 안에서 발생하는 상황을 걱정하지 않고 그룹의 부하(load)를 다른 그룹으로 이동한다.

Scheduling group: cpu 의 묶음 (하나 또는 그 이상의 cpus), 하이퍼 스레딩이 되는 cpu나,
smp 나 numa 영역 단위 등으로 다양하게 묶일 수 있음. (상황에 따라 다르게 그룹이 될 것이라고 생각하고 있다)

Scheduling class: 코어 스케줄러를 돕는 여러 모듈을 연결해 놓은 고리처럼 볼 수 있다. (정책과 구현의 분리)
각 스케줄러 모듈은 스케줄러 클래스 구조체(struct sched_class 로 존재)가 제안하는 기능을 콜백 함수처럼 구현한다.
(리눅스 코드 참조)

스케줄링 영역은 계층적으로 구성될 수 있다.
예)
하이퍼 스레딩 수준 영역 < 물리적 프로세서 수준 영역 < 누마 노드 수준 영역
하이퍼 스레딩 수준 영역 < 물리적 프로세서 수준 영역 < 프로세서 소켓 (클러스터) 수준 영역 < 누마 노드 수준 영역
등등 가능하다.

각 스케줄링 영역 특성에 맞는 스케줄러 정책 활용이 가능.

================================================================================
2014.11.22

선점형 커널에서 스케줄러 호출 시점.
1. 프로세스가 TASK_RUNNING상태가 되면 현재 실행 중인 프로세스보다 동적
   우선순위가 높다면 current 실행을 중단하고 스케줄러 호출.
2. 프로세스가 주어진 타임퀀텀을 모두 사용했을때 thread_info 자료 구조의
   NEED_RESCHED flag가 설정되며, 타이머 인터럽트 핸들러가 끝날때 호출.

================================================================================
2014.12.13
리눅스 커널 내부 구조.
p.76 스케줄러가 호출 되는 시점
1. 클럭 인터럽트의 서비스 루틴이 종료될 때 현재 수행되고 있는 task의 
need_resched 필드를 살펴보고 호출
2. 새로 생성된 태스크가 선점되야 할 경우
3. 현재 수행되고 있는 태스크가 자신의 타임 슬라이스를 모두 소진한 경우
4. 현재 태스크가 sched_setscheduler() 같은 시스템 콜을 호출할 경우

Documentation/scheduler/sched-arch.txt
Context Switch 시 run queue의 lock과
CPU idle 상태에 대한 규칙이 나타나 있는데, Idle 상태에 대한 지식이 없어
실제적으로 이해하기가 힘들다. 나중에 다시 볼것

Documentation/scheduler/sched-design-CFS.txt
vruntime : nice(priority)에 따른 weight를 반영한 가상의 cpu 사용 시간. 동일한 time slice에 대해
weight가 높을 수록 vruntime은 적게 증가할 것이고, 낮을 수록 vruntime은 빠르게 증가할 것이다.
http://studyfoss.egloos.com/viewer/5326671

timeslice를 0.01이라고 가정
 W0/WP vruntime -->
A(0.1) 0 0.001 0.001           0.002 0.003 0.004 0.004 0.005
B(0.3) 0 0     0.003           0.003 0.003 0.003 0.006 0.006
C(1)   0 0     0.01            0.01  
D(3)   0 0     0     0.03        
E(9)   0 0     0          0.09        
실행순서는 다음과 같을 것이다.
A-B-C-D-E-A-A-A-B-A-A-A...

/proc/sys/kernel/sched_min_granularity_ns
를 보면 schedule 최소 단위가 나오는데 desktop의 경우
1000000 (= 1ms) 정도가 된다. server군의 경우 더 큰 값일 것으로 추정된다.

SCHED_BATCH 또한 CFS 로 운용된다
이런 디자인상 fiftyp.c, thud.c, chew.c, ring-test.c, massive_intr.c과 같은
공격에 강하다고 하는데, 정확히는 모르겠다.

Schedule Class => Stop, RT, Fair, Idle

* CFS Schedule Class의 하부 policy로는
SCHED_NORMAL(SCHED_OTHER)
SCHED_BATCH, 선점당하지 않고 일을 처리하고 가끔 일반 태스크 실행. 상호작용에 비용듬
SCHED_IDLE, nice 19보다 더 약하다고 하는데 정확한 존재이유는 잘 모르겠음

* RT의 하부 policy로는 
SCHED_FIFO
SCHED_RR

100 개의 runqueue가 존재하며(priority갯수 만큼) 이는 예전에 140개에서 CFS가 생긴만큼
줄어든 것이다. 그리고 expired array가 없다고 하는데 추가 확인이 필요하다.
 - enqueue_task : scheduling entity(task)를 rb tree에 넣음. nr_running 증가
 - dequeue_task : rb tree로부터 뺄때 호출됨. nr_running 감소
 - yield_task : 기본적으로 dequeue한 후 enqueue한다. compat_yield일 경우 트리의 맨 오른쪽으로 이동?
 - check_preempt_curr : 지금 running task가 preempt여야 하는지 체크하는 함수
 - pick_next_task : 다음에 run될 task 선택
 - set_curr_task : scheduling class가 변경되거나 task group이 변경될때 호출되는 함수 
 - task_tick : time tick마다 불려지는 함수

CONFIG_CGROUP_SCHED : group scheduling 사용 유무 
- CONFIG_RT_GROUP_SCHED : group scheduling을 RT에 적용
- CONFIG_FAIR_GROUP_SCHED : group scheduling을 FAIR에 적용
Cgroup 설정 예제는 sched-design-CFS.txt 참조 

================================================================================
2014.12.20
----------------
Documentation/scheduler/sched-domains.txt
* sched_domin
 -span (cpu를 포함)
* sched_group
 -groups (모든 group의 합집합은 span)

* load_balance() - 현재 sched domain에서 가장 바쁜group을 찾고, 다시 가장 바쁜 런큐(cpu)를 그 그룹에서
찾는다. 그리고 현재 cpu의 런큐와 찾은 런큐를 모두 락을 걸고, 찾은 가장 바쁜 큐에서 task들을 가져온다.
이동된 task의 양은 이전 sched domain 그룹에서 계산된 값들이다. 

* SMT(hyper thread) -> SMP -> NUMA
physical cpu - core? chip 하나?
* domain 구조 두가지
#define ARCH_HASH_SCHED_TUNE
#define ARCH_HASH_SCHED_DOMAIN

* Big.Little은 AMP인가? 에 대해 궁금해 하다가...
Big.Little, cluster migration, MP(HMP), CPU migration
8core -> 4 core/ 4 core cpu migration
http://gamma0burst.tistory.com/613
결과적으로 H/W는 AMP, S/W는 SMP 처럼 보인다.

----------------
sched-nice-design.txt
* time slice와 hz에 기반해서 nice 가 동작했기 때문에 예전 스케줄러에서 잘 동작하지 않았음
* O(1)에서 기존 2.4에서 보다 - nice값의 기울기를 조정하여 더 강하게 만듬
* nice에 대한 3가지 불만 
 - 1. +19의 경우 1ms 정도가 맞지만 그러면 rescheduling비용이 너무 증가하니 5ms정도로 함. 그랬더니 너무 많은 cpu를 차지함
 - 2. 상대적인 nice 값의 차이가 구간별로 다른 차이를 나타냄
 - 3. 버그 있는 RT가 FIFO로 돌때 뒤의 nice에게는 기회가 안옴

 * 신규 스케줄러
 - 1. Hz와 time slice(jiffy)의 값에 따라 +19가 1초당 차지하는 cpu 점유율이 변하게 되었는데
 이를 time slice와 Hz와 분리하여, +19는 1.5%의 cpu 점유율을 가지도록 함
 - 2. nice의 값 차이에 따라 어느 구간이던 같은 비율을 유지하도록 함
 - 3. FIFO에 비해 강력하지 못할때, 자동적으로 recalibrate하여 nice level을 조정한다.

----------------
 * sched-rt-group.txt
- period : 수행되야 하는 주기
- runtime : 수행 주기동안 차지하는 cpu time
/proc/sys/kernel/sched_rt_period_us: 1000000 (전체 cpu bandwidth)
/proc/sys/kernel/sched_rt_runtime_us: 950000 (최대 rt가 사용할수 있는 시간)

CONFIG_RT_GROUP_SCHED, cgroup으로 group scheduling 사용
현재의 문제점. sibling 끼리의 starvation.
나중에 SCHED_EDF(Earliest Deadline First scheduling)가 나오면 해결되겠지만, 힘들어 보인다.

================================================================================
2015.01.03
----------------
Documentation/scheduler/sched-bwc.txt

SCHED_NORMAL 에서 schedule group 들의 CPU bandwidth 를 제어하는 방법을 설명한다.
각 그룹에게 quota 와 period 를 지정해서 CPU bandwidth 를 지정해 줄 수 있다.
- period (microseconds): 각 period 마다 CPU time 의 quota 만큼의 bandwidth 를 사용.
- quota: schedule group 이 소비할 수 있는 CPU time bandwidth
- runtime: 작업을 하는데 소비된 시간
- unused runtime: 주어진 bandwidth 에서 runtime 을 수행하고 남는 시간
unused runtime 은 global 하게 추적되고 period 마다 초기화된다. 이러한 시간들은
"slice" 로 관리된다.

bandwidth 를 초과하면 throttled 되고 다음 period 가 시작될 때까지 스케줄 되지
않는다. period 가 얼마나 수행되었는지, throttled 가 얼마나 되었는지 등은
통계로 남는다 (read-only).

cfs_quota_us 나 cfs_period_us 들은 cgroupfs 를 통해 지정될 수 있다.
기본값은 period = 100ms, quota = -1 이다.
quota 의 음수 값은 제약사항이 없다는 것을 의미한다.

양수 값을 통해 period 와 quota 를 지정할 수 있지만 (maximum period = 1ms)
cgroup 특성 상 계층적으로 schedule group 이 나뉘어져 있으면 추가적인 제약사항들이
생긴다 (예를 들어, 부모의 quota 에 종속적이다).

기타 다양한 제약 사항을들을 groupfs 들을 통해 관리하며, 이러한 내용들이
documentation 에 설명되어 있다.

----------------
Documentation/scheduler/sched-stats.txt
statistics 관련 문서 분석은 생략한다.

================================================================================
2015.01.10
----------------
sched_init() 코드 분석 계속 중

================================================================================
2015.01.24
RUC
https://app.box.com/shared/x5r7ugx6o6
https://www.efficios.com/pub/rcu/urcu-main.pdf 저널 논문 (이 자료가 젤 좋음)

mutex: 오직 하나의 writer 혹은 reader만 접근 가능(writer, reader의 구분이 의미없음)
rwlock: write lock과 read lock이 존재하며, write lock이 걸려 있으면 read를 못하고,
  read lock이 걸려 있으면, write를 못한다. read가 더 빈번하게 일어나므로 write lock을
  못 걸어서 굶을 확률이 크다. pthread_rwlock...
RCU: lock free이며, writer(updater)와 reader는 아무 제약 없이 진입하며,
  reader가 이미 진입하여 자료를 참고 하고 있을때 writer가 진입한다면, reader가 계속
  그 자료를 이용할 수 있게 변경하고(list, hlist자료구조가 유리),
  실제 삭제는 해당 자료를 참조하고 있는 reader가 사라질 때
  삭제한다. 한마디로 자료 갱신 부분에서 동기화를 맞춘다고 보면 된다.
user level에서 사용하기 어려운 이유:
http://bartoszmilewski.com/2013/11/13/functional-data-structures-in-c-lists/
http://summerlight.tistory.com/entry/동기화-기법-Read-Copy-Update

hlist 잠깐
사용 이유.
head에서 tail을 사용하지 않고,
hnode에서 **prev를 사용함으로서 갱신시 head의 정보를 넘길 필요 없고,
if check가 없어짐
http://stackoverflow.com/questions/3058592/use-of-double-pointer-in-linux-kernel-hash-list-implementation

**prev는 자신의 앞 노드를 바로 가리키는 것이 아니라
자신의 앞 노드의 주소를 가리킨다.

================================================================================
2015.01.31
scheduling entry point
  - rt(init_rt_bandwidth 안에...)
    sched_rt_period_timer : monotonic
  - cfs(init_cfs_bandwidth) - CONFIG_FAIR_GROUP_SCHED가 define되어 있을 경우
    sched_cfs_period_timer : monotonic
    sched_cfs_slack_timer : monotinic

  - 공통 (init_rq_hrtick)
    hrtick : monotonic

hr timer의 clock base는 4개가 미리 만들어져 있다 . kernel/hrtimer.c
HRTIMER_BASE_MONOTONIC, HRTIMER_BASE_REALTIME, HRTIMER_BASE_BOOTTIME, HRTIMER_BASE_TAI
time값을 얻어 오는 함수는 다음과 같다.
ktime_get, ktime_get_real, ktime_get_boottime, ktime_get_clocktai
MONOTONIC과 BOOTTIME의 차이는 둘다 시스템 시작후의 시간을 가리키는데,
BOOTTIME은 suspend된 시간까지 포함한다. kernel/time/timekeeping.c

TAI : International Atomic Time

kernel/sched/fair.c - sched_cfs_period_timer

GTOD - generic time of day

===============================================================================
Documentation/timers/highres.txt

- The paper "hrtimers and beyond"
www.kernel.org/doc/ols/2006/ols2006v1-pages-333-346.pdf

- The paper "We Are Not Getting Any Younger: A New Approach to Time and Timers"
www.kernel.org/doc/ols/2005/ols2005v1-pages-227-240.pdf

clock
 - clock source: 단조롭게 증가하는 시간 정보를 읽어옴
 - clock event device: 다음 이벤트 인터럽트 스케줄에 사용(paper에서는 clock evnt source)

1) hrtimer base infrastructure
timer wheel과 달라진점은 rb-tree를 이용한 정렬된 큐잉과 tick과 독립적으로 됨

2) timeofday and clock source management
"We Are Not Getting Any Younger: A New Approch to Time and Timers"에서
John Stultz의 GTOD(Generic Time Of Day) framework로 기존의 TOD가 architecture specific한
부분에서 바깥으로 나오게됨("hrtimers and beyound" fig.3) 2.6.18에 적용

3) clock event management
현재까지는 다음 이벤트에 대한 정의는 주기적으로 정의 되어 있으며,
이는 컴파일 타임에 정의 되고 이는 아키텍쳐에에 의존적인 코드로 되어 있다.
중복된 코드로 인해 설정을 바꾸는 것이 아주 어려웠다. 그리고 hrtimer를 지원하기 위해서는
모든 곳을 손봐야 했다.
이를 해결하기 위해 clock event sybsystem이 나오게 되었고, 아키텍쳐 의존적인
코드를 최소화하고 새로운 clock event 장치를 쉽게 추가 활용할수 있도록 목표를 잡고있다.

per-system global event device : linux periodic tick(jiffies update)을 위해 사용
per-CPU event devices : 각 cpu의 process accounting, profiling, high resolution timers에서 사용

clock event device의 management layer가 해야 하는일
  - system global periodic tick (jiffies update)
  - cpu local update_process_times
  - cpu local profiling
  - cpu local next event interrupt (non periodic mode)

clock event device의 clock event layer에서 할수 있는일
  - 다음 event interrupt 스케줄하기
  - notification service
  - suspend & resume

이 변경으로 인해 기능상의 충격은 없었으며, high resolutin timer와
dynamic tick을 이용할수 있게 되었다.
이는 아래의 kernel 설정을 enable함으로서 사용할 수 있다.
high resolution timers
dynamic tick
dynamic tick에서 idle routine 호출

Fig #4 참조

================================================================================
2015.02.07
Cont.
4) high resolution timer functionality
부팅 도중에 high resolution timer기능을 사용하는 것은 불가능하고, 유용하지 않다.
clock event device framework 와 GTOD와 hrtimers는 스스로 초기화되며,
그전에 clock soruces와 clock event devices 또한 등록 되어있어야 한다.
hrtimer가 초기화되기 전까지 lor resolution periodic mode로 동작하며, 새 하드웨에 대해
hrtimer가 사용가능해지면 notification을 해준다. hrtimer는 high resolution mode로
동작하는지 검증해 보고, 제대로 지원되지 않는다면 그냥 low resolution mode로 동작한다.

global clock event device만 지원되는 SMP에 대한 high resolution 지원 코드는 없다.
그것은 IPI call과 관련이 있는데, overhead가 너무 커서이다
i386 SMP에서는 C3 power state에 있는 APIC을 멈추게 하기에 high resolution과
dynamic tick을 멈출수 없다.
timer가 추가될 때 event deivce가 재프로그램되는 것을 결정할수 있다.
한군데서만 사용되는듯하다. (이해 안가서 생략)
timer interrupt 가 발생하면 rb tree로 부터 linked list로 옮기고, softirq handler를
호출한다. hard interrupt context에서는 이것이 제한되어 있는데, 여기서는
context switching을 피하기 위해서 사용한다. wakeup function에서 사용한다.
high resolutin mode가 되면 periodic tick이 꺼진다. 이것은 system global periodic clock을
사용못하게 한다.(위의 i386 SMP와 관계 있는듯 한데 잘 모르겠다.)
per-cpu hrtimer로 periodic tick 기능을 운용한다.
이하 생략

5) dynamic ticks
- hrtimer_stop_sched_tick
- hrtimer_restart_sched_tick
- hrtimer_update_jiffies

full tickless를 위해 남은 구현 사항
(일단 생략)
===============================================================================
Documentation/timers/hrtimers.txt
(조금 생략)
timer wheel 구조
http://www.ibm.com/developerworks/aix/library/au-lowertime/

cascading 방식
http://lwn.net/Articles/152436/
tv자료구조를 계속 만들면서 추가한다.

high resolution timer를 새로만든 이유 4가지
1) jiffies값과 너무 엮여 있고, 32bits로 가정하고 만들었기에 확장하기 힘들다
2) tier wheel의 cascading 방식은 delay를 예측할수가 없다
3) settimeofday나 NTP에서 이미 사용하고 자료구조는 너무 경직되어있다.
4) timer wheel 은 I/O 에러 상태를 검사하는 timeouts에 최적화되어 있는데
이는 대부분 expire되지 못하고 그전에 제거된다. 게다가 사용자들은 granularity와
정확성의 trade off를 받아들일수 있다.(덜 정확해도 문제없었다)
(granularity가 증가할수록 정확도가 올라가지만 성능이 떨어짐) 
그리고 오버헤드가 거의 없을것으로 예측했다.(?)
정확한 timing은 중요목표가 아니었다. - 사실 timeout value는 대강 설정했었다.
이것은 비용이 적게들고 간섭덜받아야하는 실제 정확한 timeout 완료 프로세싱을 보장하는데 필요악이었다.

================================================================================
2015.02.28
Documentation/timers/hrtimers.txt 계속
timeout과 precise timer subsystem의 분리는 많은 이점이 있다.
ex) 저해상도 timer에서도 정밀한 부분이 요구되면 hrtimer코드로 migrate시킬 수 있다.

hrtimer subsystem 구현 상세
- 간단하게...
- jiffies와 granularity에 의존하지 않고, 64 bits nanoseconds로 동작하게.
- 이미 존재하는 커널 코드와 단일화

즉각적인 큐에 넣기와 ordering을 위해 rbtree를 선택했다.
예전의 low-resolution CLOCK_REALTIME은 시간 변경이 발생하면
모든 timer를 하나씩 deque, enque하면서 처리해야 했다.

ktime_t: union 으로 되어 있으며 32bits system에서는 struct 두개로 구성되어 있다.
include/linux/ktime.h 참조. ktime_t -> timeval 등의 변환 함수, 매크로가 있다.

hrtimer에 영향을 받는 커널 기능
 - nanosleep
 - itimers
 - posix-timers

===============================================================================
Documentation/timers/hpet.txt
intel과 ms가 만들었다.
이하 생략

Process Scheduling in Linux (PDF)
http://criticalblue.com/news/wp-content/uploads/2013/12/linux_scheduler_notes_final.pdf
Linux Process Scheduling (PDF)
http://criticalblue.com/news/wp-content/uploads/2013/12/linux_scheduler.pdf

Process Scheduling in Linux (PDF) 의
5. Scheduler Skeleton chapter를 보기 시작

- kernel/sched/core.c -> __sched()  함수 분석
preemt_disable로 만들고, rq lock을 걸고, next task를 찾고
context_switch()를 실제로 실행하는 함수

다음 시간에는 위의 pdf를 마저 보거나, __sched함수를 더 자세히 분석하거나,
context_switch() 함수를 더 자세히 분석하자.

================================================================================
2015.03.07
Process Scheduling in Linux (PDF) 계속

5.2 Calling the Scheduler (schedule()을 호출하는 경우 3가지)
- 1. scheduler_tick() 에서 task_tick()에서 호출
- 2. sleep 상태로 갈때 - wait_queue에 넣고 schedule() 함수를 호출하여 잠들어 버림.
  signal 받으면 loop를 빠져나옴
- 3. wake_up - ttwu_queue()의 activate_task()에서 queue를 옮기고 check_preempt_curr() 에서 resched()

6. Short Scheduling Algorithm History
- kernel 1.2 : Circular Runqueue RR
- kernel 2.2 : scheduling class (rt-tasks, non-preemptible, non-rt tasks), SMP
- kernel 2.4 : O(N) scheduler
- kernel 2.6 : O(1)
- kernel 2.6.23 : CFS

7. CFS
- 앞부분 요약 생략
- Text Editor와 Video Encoder의 예. CFS를 사용하면 I/O bound와 CPU bound task 모두 조화롭게 사용할수 있다.
7.4 Spawning a new Task
- 새로운 task가 생성되면 vruntime_min 같을 가져올 것으로 추정
7.5/ 7.6 요약 생략

8 CFS Implementation Details
8.1 Data Structures
  struct sched_entity{}, task->se로 존재
  struct cfs_rq{}, rq->cfs_rq로 존재
8.2 Time Accounting
  - kernel/sched/core.c: scheduler_tick() -> task_tick() -> fair/ task_tick_fair()
  - cfs_rq의 se(sched_entity)를 돌면서 entity_tick()을 호출
    - entity_tick() : update_curr()을 통해 current task의 runtime 갱신
    - check_preempt_tick(): resched check - current task가 left most보다 크고, latency runtime보다 클 때
  
다음 시간은 8.3 Modifying the Red-Black-Tree 서부터 할 차례
자세한 코드 분석은 문서를 모두 읽고 난 후에 하기로 함
================================================================================
2015.03.21
Top Half/ Bottom Half(SoftIrq, Tasklet)
http://www.makelinux.net/books/lkd2/ch07lev1sec1
http://www.makelinux.net/books/lkd2/ch07lev1sec2 

schedule_tick() 호출 하는 path 2가지.
1) init/main.c - start_kernel()
    -> kernel/timer.c - init_timers() : open_softirq - run_timer_softirq 등록
    --------------------------------------------------------------------------
      ->  kernel/timer.c - run_timer_softirq()
        ->       "        -  hrtimer_run_pending()
          ->        "       - hrtimer_switch_to_hres()
            ->  kerne/time/tick-sched.c - tick_check_oneshot_change()
              ->    "           - tick_nohz_switch_to_nohz()
	              -> 어딘가에서 hires oneshot 혹은 nohz timer 호출(아마 clock source 드라이버)

                -> tick_sched_handle(struct tick_sched *ts, struct pt_regs *regs)
                  -> update_process_times(user_mode(regs));
                    -> scheduler_tick();

================================================================================
2015.03.28

kernel/time/tick-common.c:
tick_periodic()
1. ktime 업데이트
2. do_timer(1):  jiffies + 1
3. update_process_times(user_mode(regs))
       scheduler_tick()
           1. sched_clock_tick();
           2. update_rq_clock();
           3. task_tick(,,);
           4. update_cpu_load_active();
           // perf 관련: http://egloos.zum.com/studyfoss/v/5634580
5. run_posix_cpu_timers(task_struct *tsk)

elf file format (and DWARF)
: http://egloos.zum.com/recipes/v/5011946

================================================================================
2015.04.11

[scheduler_tick() 분석]

kernel/event/core.c
perf_event_task_tick()
1. perf_throttled_seq (percpu 변수) 와 perf_throttled_count (percpu 변수) 값 재설정
2. rotation_list (percpu list) 를 돌면서 perf_adjust_freq_unthr_context() 수행
    perf_adjust_freq_unthr_context(): untrottled 되야 하는 이벤트가 있거나,
    frequency mode 인 이벤트가 있다면 해당 이벤트들의 샘플링 주기를 다시 계산해준다.

rq->idle_balance = idle_cpu(cpu);
trigger_load_balance(rq, cpu);
rq_last_tick_reset(rq);
로드 밸런싱을 trigger 하고, tick 변수 세팅.

[run_posix_cpu_timers(struct task_struct* tsk) 분석]
POSIX 표준을 위한 타이머 값 갱신

================================================================================
2015.04.18

[run_posix_cpu_timers(struct task_struct*tsk)] 분석 중.

================================================================================
2015.04.25

[run_posix_cpu_timers(struct task_struct*tsk)] 분석 중.

================================================================================
2015.05.05

[run_posix_cpu_timers(struct task_struct*tsk)] 분석 중.
cpu_timer_fire(): firing list 의 있는 task 들을 처리
4 가지 case 에 대해서,
2 번째 case: nanosleep 을 사용하는 task 일 경우
-- wake_up_process() 분석 완료.

================================================================================
2015.06.06
- init/main.c/star_kernel/idr_init_cace()
  IDR : Id(정수)와 pointer 관리
  http://egloos.zum.com/studyfoss/v/5187192
  IDR_BITS 8 => 8 bits씩 끊어서 하나의 layer로 관리한다.
  32 bits 에서는 4 depths 가 만들어진다.
  Java의 SparseArray와 비슷한 느낌이다.
- RCU 다시 시작 (rcu_init())
  다음 시간 부터 Documentdation/RCU 보기로 함.

================================================================================
2015.06.13

- Bottom Halves 구현 종류 (http://www.makelinux.net/books/lkd2/ch07lev1sec1)
  - BH 2.5에서 제거
  - Task queues 2.5에서 제거
  - Softirq 2.3 추가
  - Tasklet 2.3 추가
  - Work queue 2.5 추가

* http://kenshin579.tistory.com/entry/interrupt-exception-trap의-차이점
- hardware interrupt(CPU제외) 
- software interrupt(실제 하드웨어 line이 아닌 code에 의해 발생)
  - exception (cpu에서 발생)
    - trap 복귀후 다음 명령 실행
    - fault 복귀후 원래 명령 다시 실행
    - abor 복귀하지 않고 종료

* memory barrier - http://forum.falinux.com/zbxe/index.php?document_srl=534002&mid=Kernel_API
  - DMB(Data Memory Barrier)
  - DSB(Data Synchronization Barrier)
  - ISB(Instruction Synchronization Barrier)

* lock의 차이
1. lock 획득후 context switch 당하지 않는가? (preempt disable)
  - mutex: 당함
  - spinlock: 안당함
  - rcu_read_lock: 안당함
  - rcu write시: spinlock 사용
2. lock 획득후 intrrupt 당하지 않는가?
  - mutex: 조사할것
  - spinlock: 조사할것
  - rcu_read_lock: 조사할것
  - rcu write시: spinlock 사용
3. lock을 획득 못한 경우 어떻게 행동하는가?
  - mutex: context switch(maybe sleep)
  - spinlock: busy waiting
  - rcu_read_lock: 이럴 경우 없음
  - rcu write시: spinlock 사용
4. 계속 조사할것

* Doucument/RCU/wahtisRCU.txt
  1. RCU Overview
  2. RCU's Core API
     a. rcu_read_lock() : read를 시작할때 사용하는 lock
     b. rcu_read_unlock() : read 완료
     c. synchronize_rcu() : read가 완료 되면 reclimation 수행(cal_rcu callback 함수를 이용할 수 도 있음) 
     d. rcu_assign_pointer() : 기존 global 포인터에 새로운 포인터 설정.
     e. rcu_dreference() : 새로 갱신된 read 값을 읽어 옮.

  3. CORE RCU API Example 분석 중 끝.

================================================================================
2015.06.20

* RCU 개념 복습

* Documentation/RCU/whatisRCU.txt: line 405 부터 시작
rcu_assign_pointer 가 atomic 하게 되어 있을 것인가?

#4. 
synchronize_rcu() - synchronous 하게 rc 자료 구조를 업데이트 한다.
다른 high-priority 한 작업들을 처리해야 할 필요가 있을때는 call_rcu() 를 통해 비동기적으로 업데이트 할 수 있다.
비동기적으로 rcu 자료 구조에  접근하기 위해서  rcu 자료 구조의 포인터를 함 packing 한다.
콜백 함수를 통해서 처리를 하는데, 실제로 kfree 만 수행하면 되는 경우ㅇ는 kfree_rcu 만 호출하는 방식을 통해 콜백 함수를 작성하지 않아도 된다.

#5. What are some simple implementations of RCU?
production-quality 관점에서 2 가지 괜찮은 초기 구현이 있었음.
여러 가지 구현 방법들이 발표되었었고, 현재 2004년에 나온 구현 방법이 쓰이고 있다.

#5.A. TOY impl. LOCKING
-- RWLOCK(mutex) 을 통해 RCU 를 구현. 가장 간단하다.

#5.B. Toy impl. 2: CLASSIC RCU
-- rcu_read_lock() rcu_read_unlock() --> do nothing
-- synchronize_rcu(void) ---> 모든 cpu 를 돌면서 (grace period 를 허용하는) synchronization 을 수행한다.
-- run_on(cpu) <- 모든 cpu 에서 한번씩 실행되도록 한다. (즉 새로 고치기 전에 값을 읽고 있던 read-side critical sections 는 모두 rcu_read_unlock() 을 수행했다는 것을 의미함) --> 비선점형 커널에서 
---- for each cpu 에 대해서 run_on(cpu) 를 수행하는 중간에서 run_on 을 이미 수행한 cpu 에서 새로 발생한 read-side critical sections 는 grace period 로 허용됨.

================================================================================
2015.07.04
http://kernelnewbies.org/FAQ/Preemption
2.4(non preemptible kernel) => 2.6 (preemptible kernel)
선점하고 있는 태스크입장: 선점당하지 않는 커널(비선점형) => 선점당하는 커널(선점형)
선점하려는 태스크입장: 선점 불가능 커널(비선점형) => 선점 가능 커널(선점형)

Quiz 1: rwlock을 이용한 rcu에서 deadlock 상황을 설명하라
CPU0(reader) 가 먼저 어떤 lock을 걸고 CPU1(writer)가 write lock을 걸고
CPU0이 writer가 끝나기를 기다릴 때 CPU1이 interrupt가 걸렸는데 마침
그 handler에서 CPU0이 이미 잡고 있는 어떤 lock을 기다릴 경우 deadlock.
해결책: CONFIG_PREEMPT_RT를 사용하면 CPU1이 interrupt가 block된 상태에서
진행하므로 deadlock이 발생하지 않는다.
그럼에도 불구하고 reader -> writer(synchronize_rcu())-> reader의 경우가 있을 때
처음 reader의 지연이 나중 reader의 지연을 발생하므로 손해가 있다.
그러므로 counter-based 접근을 사용해야 synchronize_rcu()에서 block되지 않는다.

Quiz 2: syncronization 에 대한 overhead를 classic RCU를 사용하면 줄일수 있다.
routing table을 조회하느라 irq disable하는 것보다 RCU를 사용하는 것이 좋다.

Quiz 3: PREEMPT_RT 에서는 spinlock이나 read-side에서 blocking을 허용한다.
RCU grace periods를 줄이기 위해 priority boosting을 사용할 가능성이 있기 때문이다.
그 이유는 잘 모르겠음

6. RCU와 rw lock과의 유사점
대부분은 같다. 그러나 RCU는 read와 write를 동시에 할 수 있다. 단, list의 update가
원자적인 것으로 보여지길 원한다면 주의 깊게 사용해야 한다.
(동시에 두가지 버전이 존재할수 있으므로.)

7. RCU API 목록
SRCU : sleepable RCU
Barrier : 어떤 의미로 필요한지 잘 모르겠음

RCU vs bh vs sched vs SRCU
http://lwn.net/Articles/264090/
자세한 차이점은 생략한다.

다음 시간은
rcu_init() 부터 다시

================================================================================
2015.07.18
jiffies : 1초에 HZ 만큼 증가하는 전역 변수. timer interrupt에 의해서 갱신된다.
overflow 대책 코드
#define time_after(a,b)		\
	(typecheck(unsigned long, a) && \
	 typecheck(unsigned long, b) && \
	 ((long)(b) - (long)(a) < 0))

실제적으로는 signed 에 대한 +, - 연산이나 unsigned에 대한 +, -연산의
bits 결과는 같다. 이에 대한 결과 bits를 signed로 읽을 것이냐 unsigned로 간주하고
읽을 것이냐에 대한 선택의 차이이다. (*, / 연산은 결과가 다름)
그러므로 다음의 매크로로 바꾸어도 같은 동작을 할것이다.
	 ((long)(b - a) < 0))

hierachical rcu
http://lwn.net/Articles/305782/
Quiescent state - grace period 후에 cpu가 최소 한번 실행된 상태
Quiescent states - grace period 후에 모든 cpu가 최소 한번 실행된 상태. grace period의 끝

classic rcu의 단점
dynamic tick으로 idle 상태인 cpu까지 quiescent state를 지나야 한다.
quiescent state가 되면 mask check를 해야 하는데 cpu가 늘어나면 lock에서 병목이 발생

real-time rcu를 위한 조건
* 생략

우리는 real-time rcu가 아니므로 real-time rcu 조건중 하나인 선점형 rcu 조건은 필요없다.

lock 집중도 문제ㄹ 해결하기 위해
lock을 여러 레벨의 rcu_node를 만들어 분산 시킨다.
아래 레벨의 cpu들이 모두 QS가 되야 상위 레벨의 QS를 체크한다.
마지막으로 QS를 완성하는 cpu가 상위 QS를 lock을 걸고 체크한다.
FanOut : rcu_node 에 달려 있는 rcu_node 혹은 cpu의 갯수

Quiz 1:
Quiz 2:
Quiz 3:
Quiz 4:


================================================================================
2015.08.08 , 2015.09.12
Kernel Config 검색, 비교
http://kernel.xc.net/

rcu_init() 다시 시작
  - rcu_init_geometry(); /* rcu_state, rcu_node를 만들기 위한 level수나 노드 갯수 계산*/
  - rcu_init_one(); // rcu_state는 현재 두개가 존재한다 sched_state, bh_state.
                    // 이를 초기화 함.
    - lockdep_set_class_and_name(); // spinlock등을 추적하기 위한 디버깅용 매크로
    - init_waitqueue_head()
      struct irq_work, irq callback fn 과 pending list?
        llist : lock-less null terminated single linked list. (선언 파일의 표는 좀 이상함)
      
* flow
call_rcu -> __call_rcu -> __call_rcu_core -> invoke_rcu_core -> raise_softirq ->
wakeup_softirqd() -> daemon이... -> rcu_process_callbacks ->

struct notifier_block; - cpu의 online, offline event를 위함
// @@ notifier 4종류.
* Atomic notifier chains : Atomic Notifier Chain Type은 Chain Callback 함수들이 Interrupt나 Atomic Context에서 동작하고 Callback 함수가 Block되는 것을 허용하지 않음.
* Blocking notifier chains : Blocking Notifier Chain Type은 Callback 함수들이 프로세스 컨텍스트에서 수행되며, Callback 함수가 Block되는 것을 허용
* Raw notifier chains : Raw Notifier Chain Type은 callback, registration, unregistration에 대한 제약이 전혀 없으며, 호출자 (Caller)에 의해서 모든 locking 및 protection이 제공되어야 함.
* SRCU notifier chains : SRCU Notifier Chain Type은 Blocking Notifier Chain의 변종으로 동일한 제약을 가짐. srcu_notifier_call_chain() 함수는 SRCU (Sleepable Read-Copy Update)를 사용하며 SRCU는 rw-semaphore 보다 chain link들에 대한 보호에서 작은 오버헤드를 가짐 (no cache bounce & no memory barrier). 이에 대한 대가로 srcu_notifier_chain_unregister()는 조금의 오버헤드가 있음. SRCU Notifier Chain들은 Chain이 빈번하게 호출되지만 Notifier Block에서 거의 제거되지 않은 경우에 사용되어야 하며,
* 사용하기 위해서는 Runtime Initialization이 필요함.

chain을 등록 (register)할 때, atomic_notifier_chain_register(), blocking_notifier_chain_register(), srcu_notifier_chain_register()를 이용하며, atomic_notifier_chain_register()는 atomic 컨텍스트에서 호출되지만, 나머지 두개는 process 컨텍스트에서 호출되어야 함. chain을 해제 (unregister) 할 때는 call chain에서 unregister 함수가 호출되면 안됨.

다음 시간은 cpu_notifier(rcu_cpu_notify + early_initcall ) 마저 보고, rcu_process_callbacks 볼 차례

================================================================================
2015.09.26

Notifier 참고사이트: http://opensourceforu.efytimes.com/2009/01/the-crux-of-linux-notifier-chains/

rcu_init() 분석 완료
rcu_init --> rcu_cpu_notify(CPU_UP_PREPARE)
  - RCU State -> RCU Node -> RCU Data : per-CPU에 있는 RCU Data값을 초기화한다.
  - RCU boost thread를 띄운다.
 
tick_nohz_init() 분석 완료
  - CPU 0번을 제외한 모든 CPU의 dynticks mask(nohz_full_mask)를 1로 설정함
  - cpu_notifier에 tick_nohz_cpu_down_callback를 등록함. CPU Down시 처리 루틴.
  - 참고사이트: http://cateee.net/lkddb/web-lkddb/NO_HZ_FULL_ALL.html

================================================================================
2015.10.03

radix_tree_init() 분석 완료
  - radix_tree_node_cachep 에 kmem_cache를 생성함.
  - height_to_maxindex 배열을 초기화한다. height_to_maxindex은 깊이에 대한 최대 인덱스값을 설정한다.
  - cpu_notifier에 radix_tree_callback을 등록함. 
  - radix_tree_callback는 CPU Dead시 radix_tree_node_cachep에 할당된 kmem_cache를 free해준다.
early_irq_init() 분석 완료
-- non-sparse irq init
-- architecture independent 한 irq_desc fields 를 초기화
init_IRQ() 분석중 (arch/arm/kernel/irq.c)
-- irqchip_init() (drivers/irqchip/irqchip.c) 분석중

2015.10.10
OpenFirmware
of_irq_init()
ex) DT : arch/arm/boot/dts/exynos5.dtsi 의 interrupt-controller 항목을 찾는다.
    combiner : drivers/irqchip/exynos-combiner.c
      IRQCHIP_DECLARE 에서 data(controller) function pointer를 설정해주고
      of_irq_init()에서 초기화 함.
APIC : Advanced Programmable Interrupt Controller
ACPI : Advanced Configuration and Power Interface

* tick broadcast framework
https://lwn.net/Articles/574962/
  - C-State : CPU Operating(Sleeping) State
=> 읽다가 멈춤

